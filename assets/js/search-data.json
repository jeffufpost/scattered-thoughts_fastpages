{
  
    
        "post0": {
            "title": "Scraping COVID-19 data from data.gouv.fr",
            "content": ". Introduction . As the summary explains, this blog post will very quickly explain how to automatically download French government data on hospitalization and testing pertaining to COVID‚Åª19. . Data sources . Hospitalization data | . The various datasets concerning hospitalization data are found here. . If you follow the link you will find 4 csv datasets concerning hospitalization data along with 5 other csv files with metadata and documentation. . Testing data | . The various datasets concerning testing data are found here. . If you follow the link you will find 2 csv datasets concerning testing data along with 2 other csv files with metadata and documentation. . In both cases we want to download the first of the links since they contain the pertinent daily updated data (do have a look manually at the metadata and documentation files to make sure this is what you want). . Code . #collapse_show # Import libraries used below import requests import urllib.request import urllib.parse import time import io from bs4 import BeautifulSoup import pandas as pd import datetime import os . . Getting the main page . Let&#39;s first have a look ath the main landing page that I provided above. . # Store URL for each page url_cases = &#39;https://www.data.gouv.fr/fr/datasets/donnees-hospitalieres-relatives-a-lepidemie-de-covid-19/&#39; url_tests = &#39;https://www.data.gouv.fr/fr/datasets/donnees-relatives-aux-tests-de-depistage-de-covid-19-realises-en-laboratoire-de-ville/&#39; . # Get response for each URL response_cases = requests.get(url_cases) response_tests = requests.get(url_tests) . The response here should be 200 (see life of codes here). . print(response_cases, response_tests) . &lt;Response [200]&gt; &lt;Response [200]&gt; . # Save the actual content of the page returned with BeautifulSoup soupcases = BeautifulSoup(response_cases.text, &quot;html.parser&quot;) souptests = BeautifulSoup(response_tests.text, &quot;html.parser&quot;) . # Let&#39;s look at the links in the main page (for testing data - if you want cases, replace souptests with soupcases below) for i in range(len(souptests.find_all(&#39;a&#39;, class_=&quot;btn btn-sm btn-primary&quot;))): print(souptests.find_all(&#39;a&#39;, class_=&quot;btn btn-sm btn-primary&quot;)[i].get(&#39;href&#39;)) . None https://www.data.gouv.fr/fr/datasets/r/b4ea7b4b-b7d1-4885-a099-71852291ff20 None https://www.data.gouv.fr/fr/datasets/r/72050bc8-9959-4bb1-88a0-684ff8db5fb5 None https://www.data.gouv.fr/fr/datasets/r/971c5cbd-cd80-4492-b2b3-c3deff8c1f5e None https://www.data.gouv.fr/fr/datasets/r/db378f2a-83a1-40fd-a16c-06c4c8c3535d https://www.data.gouv.fr/fr/datasets/r/49ba79e6-0153-40b1-b050-821e102959eb None https://www.data.gouv.fr/fr/datasets/r/59e82d52-e07a-4ae8-9a49-2d1fd2d2ec21 . We see that the petrtinent file in each cases (testing or hospitalization data) are the first links in their page. So we save only this one as donw below: . # If we want to save that first URL we can do as follows casescsvurl = soupcases.find_all(&#39;a&#39;, class_=&quot;btn btn-sm btn-primary&quot;)[1].get(&#39;href&#39;) testscsvurl = souptests.find_all(&#39;a&#39;, class_=&quot;btn btn-sm btn-primary&quot;)[1].get(&#39;href&#39;) . Getting the CSV data . We now have the URL for the CSV files we want so we&#39;ll do similar steps as above to download these files. . # Similaraly as above, requests.get the CSV URL: rectests = requests.get(testscsvurl) reccases = requests.get(casescsvurl) . What to do with the CSV data . Now that you have the data, what to do with it? . It depends on your purpose I guess: . First write the data to a CSV file which you then read | Directly read the data | . By first writing the CSV file to drive . # This will write the data into cases.csv file # Of course you need to replace the actual path to the folder you want in the code below: with open(os.path.join(&quot;/path/to/folder&quot;, &quot;cases.csv&quot;), &#39;wb&#39;) as f: f.write(reccases.content) . # Same thing for testing data # This will write the data into tests.csv file # Of course you need to replace the actual path to the folder you want in the code below: with open(os.path.join(&quot;/path/to/folder&quot;, &quot;tests.csv&quot;), &#39;wb&#39;) as f: f.write(rectests.content) . # You can then read that csv file to use in your data analysis: tests = pd.read_csv(&#39;tests.csv&#39;, sep=&#39;;&#39;, dtype={&#39;dep&#39;: str, &#39;jour&#39;: str, &#39;clage_covid&#39;: str, &#39;nb_test&#39;: int, &#39;nb_pos&#39;: int, &#39;nb_test_h&#39;: int, &#39;nb_pos_h&#39;: int, &#39;nb_test_f&#39;: int, &#39;nb_pos_f&#39;: int}, parse_dates = [&#39;jour&#39;]) cases = pd.read_csv(&#39;cases.csv&#39;, sep=&#39;;&#39;, dtype={&#39;dep&#39;: str, &#39;jour&#39;: str, &#39;hosp&#39;: int, &#39;rea&#39;: int, &#39;rad&#39;: int, &#39;dc&#39;: int}, parse_dates = [&#39;jour&#39;]) . Note in the code above I had previously looked through the raw csv data to underdstand how to parse it. . Directly reading the data (bypassing the writing CSV file step) . cases = pd.read_csv(io.StringIO(requests.get(casescsvurl).content.decode(&#39;utf-8&#39;)), sep=&#39;;&#39;, dtype={&#39;dep&#39;: str, &#39;jour&#39;: str, &#39;hosp&#39;: int, &#39;rea&#39;: int, &#39;rad&#39;: int, &#39;dc&#39;: int}, parse_dates = [&#39;jour&#39;]) tests = pd.read_csv(io.StringIO(requests.get(testscsvurl).content.decode(&#39;utf-8&#39;)), sep=&#39;;&#39;, dtype={&#39;dep&#39;: str, &#39;jour&#39;: str, &#39;hosp&#39;: int, &#39;rea&#39;: int, &#39;rad&#39;: int, &#39;dc&#39;: int}, parse_dates = [&#39;jour&#39;]) . Other stuff . Parsing/Converting URI into readable format . It sometimes happends that links are provided in URI (URL symbols encoded into % symbols...) . You generally need to convert those back to correct URLs, example below: . # Example URI testurl = &#39;https%3A%2F%2Fstatic.data.gouv.fr%2Fresources%2Fdonnees-hospitalieres-relatives-a-lepidemie-de-covid-19%2F20200505-190040%2Fdonnees-hospitalieres-covid19-2020-05-05-19h00.csv&#39; . # Convert with following line: urllib.parse.unquote(testurl) . &#39;https://static.data.gouv.fr/resources/donnees-hospitalieres-relatives-a-lepidemie-de-covid-19/20200505-190040/donnees-hospitalieres-covid19-2020-05-05-19h00.csv&#39; . A quick look at French testing data from scratch . Let&#39;s quickly see how, from scratch, we can use code above to scrape testing data and plot it quickly. . Note the data only includes city testing centers and does not include hospital testing. . # Use main page URL url_tests = &#39;https://www.data.gouv.fr/fr/datasets/donnees-relatives-aux-tests-de-depistage-de-covid-19-realises-en-laboratoire-de-ville/&#39; response_tests = requests.get(url_tests) . # Find correct CSV file URL souptests = BeautifulSoup(response_tests.text, &quot;html.parser&quot;) testscsvurl = souptests.find_all(&#39;a&#39;, class_=&quot;btn btn-sm btn-primary&quot;)[1].get(&#39;href&#39;) . # Read CSV file into tests variable rectests = requests.get(testscsvurl) tests = pd.read_csv(io.StringIO(requests.get(testscsvurl).content.decode(&#39;utf-8&#39;)), sep=&#39;;&#39;, dtype={&#39;dep&#39;: str, &#39;jour&#39;: str, &#39;hosp&#39;: int, &#39;rea&#39;: int, &#39;rad&#39;: int, &#39;dc&#39;: int}, parse_dates = [&#39;jour&#39;]) . #collapse_hide import plotly.express as px import plotly.graph_objects as go # We want overall testing for France, se we groupby Day and sum: (filtering for clage_covid = 0 means not differentiated between age groups) df = tests[tests.clage_covid==&#39;0&#39;].groupby([&#39;jour&#39;]).sum() fig = go.Figure(data=[ go.Bar(name=&#39;Positive tests&#39;, x=df.index, y=df.nb_pos, marker_color=&#39;red&#39;), go.Bar(name=&#39;Total tests&#39;, x=df.index, y=df.nb_test, marker_color=&#39;blue&#39;) ]) fig.update_layout( title= &#39;Daily positive and total testing data in France&#39;, xaxis_title = &#39;Date&#39;, yaxis_title = &#39;Number of tests (total and positive)&#39;, barmode=&#39;group&#39; ) fig.show() . . . . Conclusion . Very easy to incorporate this into a python script to automate. . This is only the very basic of scraping, a lot more could be done, maybe in another blog post. .",
            "url": "https://jeffufpost.github.io/scattered-thoughts/scraping/covid-19/2020/04/15/web-scraping.html",
            "relUrl": "/scraping/covid-19/2020/04/15/web-scraping.html",
            "date": " ‚Ä¢ Apr 15, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "Testing - what to be aware of",
            "content": ". Motivation for write-up . The real-world motivation for this write-up can be found under Story Time section, but I first wanted to give a bit of theoretical background here. . The importance of testing has been greatly talked about these last few weeks/months with the emergence of the COVID-19 pandemic with numerous articles being published, all underlining the importance of testing. The part emphasized is the fact that early testing allows for quick isolation of sick individuals and tracing of their potential contacts, and thus limiting the potential for spread. . The kind of test for this are called virologic testing and test directly for the presence of virus in an individual (active infection). This is done with Nucleic Acid Tests, or NAT, usually after amplification of the very small amount of genetic material present via Polymerase Chain Reaction. Results are available within hours or days and require diagnostic machinery and specialists. . Knowing who has been infected is also important as it could allow already recovered patients (who are thought to gain immunity from COVID-19) to return safely to work and live basically normally. Tests that check for past infections exist, and are called serology or antibody tests. They check for specific antibodies that match those deveopped during an immune response response against SARS-CoV-2. . This is all good in theory, but with a disease that can cause such serious conditions as COVID-19 can, we need to be sure a positive test means for certain that person is now immmune, or we risk allowing individuals with false positives to return to normal when they should not, and continue the damaging spread of the disease. . The aim of this short right-up is to clear up some misconceptions around testing protocols, discuss the importance of false positives, false negatives, and its importance to guiding public health policies. The idea is basically to answer the following questions: . How many tests should return positive for a person to be, say 95% or 99% person sure he is now immune? | What if a different test is negative? | . Specificity, Sensitivity, False positives, False negatives? . As briefly explained above, neither virological and serological tests are infallible. False positives i.e. healthy individuals with a positive test, and false negatives i.e. infected indiviuals with negative tests, can, and do happen. . There are numerous reasons how and why this can happen, but that is not the point of this write-up. Here, we acknowledge the fact non-perfect tests are a reality and establish testing protocol to deal with that fact. . Thankfully, before being shipped out, the various laboratories test their tests. They are able to characterize them rather precisely and give an indiction of how useful they may be with two important values: . Specificity | Sensitivity | . Specificity . Specificity is the true negative rate - i.e. the percentage of healthy people correctly identified as such (for antibody testing, it is the percentage of people not having antibodies correctly identified as such). . In other words, if a test was used on 100 people who do not have antibodies, the number of people correctly identified as not hvaing antibodies is the specificity. . A perfect test with 100% specificity, means there are no false positives. This has major implications in the current context of COVID-19 pandemic as having an anitbody test with 100% specificity would allow immune people to know so for certain (as long as research showed antibodies gave immunity). . Mathematically, we pose specificity as follows: . $Specificity = frac{True negatives}{True negatives + False posiives}$ . Sensitivity . Sensitivity is the true positive rate - i.e. the percentage of infected people correctly identified as such (for antibody tests, it is the percentage of people having antibodies correctly identified as such). . In other words, if an antibody test was used on 100 people with antibodies, the number of people correctly identified as having anitbodies is the sensitivity. . A perfect test with 100% sensitivity, means there are no false negatives. . Mathematically, we pose specificity as follows: . $Sensitivity = frac{True positives}{True positives + False negatives}$ . Prevalence . Prevalence is simply the proportion of a population that has a certain characteistic. In the current context of antibody testing, the prevalence will be defined as the proportion of people who have antibody conferring immunity to COVID-19 (i.e. the proportion that has had the disease). . $Prevalence = frac{ # People with antibodies}{Total number of people}$ . Where $Total number of people$ is simply $ # People with antibodies + # People without antibodies$ . Story time - Part 1 . Specificity, sensitivity, prevalence, false negatives, false positives.. This is all good, but it can be a bit abstract outside of a specific testing context. . Let&#39;s use the current COVID-19 pandemic as an example. . Antibody tests are finally becoming available to the general population, and you want to know if you&#39;ve had the disease (developped antibodies against it). . Now let&#39;s say you had influenza like symptoms back in January or February, would you expect a positive or negative result on the test? | What if you haven&#39;t been sick but want to check out of curiosity, what result would you expect? | If it does come back positive, how certain would you be that you actually have those antibodies and it wasn&#39;t a false positive? | You decide to use a second test to make sure, again it comes positive. Now how certain are you that you have antibodies? | Out of extreme precaution you decide to try a test from another laboratory (different specificity and sensitivity), and this time the test comes back negative. It&#39;s become a bit more complex to evaluate your situation now. | So how about another test from this second laboratory? Again, negative.. Two positives, two negatives - what can you make of this information? | . However far fetched this scenario may seem, it is exactly what happened to this Florida physician: In January I got very sick (flu like illness but much worse), no sleep for 2 days and almost checked myself into the ED. Had no idea what it was. Today I checked my #COVID19 Antibody status......IgG+ Only (sign of past infection). Mixed emotionsüôÑ. Will retest tomorrow. pic.twitter.com/ExLYi5qPBx . &mdash; Peter Antevy (@HandtevyMD) April 2, 2020 . There are two questions that come out of this story: . After those 4 tests, what is the probability that Dr. Antevy has those antibodies - or more generally, can we calculate the probability of someone having antibodies given their test results? | What should be the threshold of such a probability to minimize the risk of someone without antibodies going out in nature thinking he does ? (obviously if someone has 10 positive tests in a row, it seems sure enough that person has antibodies) This pushes for the need of rigorous testing protocol. | . Calculating probabilites given test results . Clearly, our objective is to calculate the probability that a person has antibodies, or: . $P(seropositive)$ . Conditional probabilities . Baye&#39;s theorem describes probabilities when given evidence. . Say a person has had some COVID-19 symptoms (dry cough, fever, loss of smell, slight fever) a few weeks ago. He might say there is a 75% chance that he had contracted COVID-19, and 25% chance it was another disease. In this case: . $P(seropositive) = 0.75$ . Now this person goes to get an antibody test. What is the probability he is seropositive given a positive or negative result? Baye&#39;s theorem allows us to write it as follows: . $P(seropositive | positive test) = frac{P(positive test | seropositive) * P(seropositive)}{P(positive test)}$ . and . $P(seropositive | negative test) = frac{P(negative test | seropositive) * P(seropositive)}{P(negative test)}$ . Note: . $P(seropositive)$ is called the prior. . $P(seropositive | positive test)$ and $P(seropositive | negative test)$ are called the posterior. . $P(Positive test)$ . Let&#39;s have a look at the probability of getting a positive test - there are 2 ways to get a positive result : . A false positive | A true positive | . $P(False positive) = P(Positive test | seronegative)*P(seronegative)$ . And . $P(True positive) = P(Positive test | seropositive)*P(seropositive)$ . So: . $P(Positive test) = P(Positive test | seropositive)*P(seropositive) + P(Positive test | seronegative)*P(seronegative)$ . Sensitivity and Specificity revisited . Earlier we saw: . $Sensitivity = frac{True positives}{True positives + False negatives}$ . And that . $Specificity = frac{True negatives}{True negatives + False positives}$ . But we can rewrite these equations as follows: . $Sensitivity = P(Positive test | seropositive)$ . And . $Specificity = P(Negative test | seronegative) = 1-P(Positive test | seronegative)$ . Re-writing the posterior probability . Using Baye&#39;s rule and the calculations above we can re-write the posterior equations as follows: . $P(seropositive | Positive test) = frac{Sensitivity*P(seropositive)}{Sensitivity*P(seropositive)+ (1-Specificity)*(1-P(seropositive))}$ . And: . $P(seronegative | Negative test) = frac{Specificity*(1-P(seropositive))}{Specificity*(1-P(seropositive))+(1-Sensitivity)*P(seropositive)}$ . The role of prevalence in these calculations . The equations above describe the probability for an individual given a test result and their prior probability. This prior probability can be estimated given presence or not of symptoms, contact with other infected individuals, location, other diagnostics, etc... . However, on a population level, if we were to test a random individual, this prior becomes the prevalence and for a random individual, the equations become: . $P(seropositive | Positive test) = frac{Sensitivity*Prevalence}{Sensitivity*Prevalence+(1-Specificity)*(1-Prevalence)}$ . And: . $P(seronegative | Negative test) = frac{Specificity*(1-Prevalence)}{Specificity*(1-Prevalence)+(1-Sensitivity)*Prevalence}$ . Serology testing simulation . Let&#39;s see what these equations look like in practice. . #collapse_hide import numpy as np import plotly.express as px import plotly.graph_objects as go . . #collapse_hide # Let&#39;s write a function to output the posterior probability given prior, test result, and test characteristics (sensitivity and specificity) def Pposterior(Pprior, test_res, Sn, Sp): if test_res: return ((Sn * Pprior) / (Sn * Pprior + (1-Sp) * (1-Pprior))) else: return (1-((Sp * (1-Pprior))/(1-(Sn * Pprior + (1-Sp) * (1-Pprior))))) . . Say we have an antibody test with 90% sensitivity and 90% specificity - meaning we have 90% true positives and 90% true negatives, we obtain a graph as below: . #collapse_hide # Below is the prior probability of being infected: num=10000 Pprior = np.linspace((1/num),(num-1)/num,num=num) # Graph the results fig = go.Figure(data=[ go.Scatter(name=&#39;Test negative&#39;, x=100*Pprior, y=100*Pposterior(Pprior, False, 0.9, 0.9), line_color=&quot;green&quot;), go.Scatter(name=&#39;Test positive&#39;, x=100*Pprior, y=100*Pposterior(Pprior, True, 0.9, 0.9), line_color=&quot;red&quot;), go.Scatter(name=&#39;No test&#39;, x=100*Pprior, y=100*Pprior, line_color=&quot;blue&quot;) ]) fig.update_layout( xaxis_title = &#39;Prior probability of being infected&#39;, yaxis_title = &#39;Posterior probability of being infected given test result&lt;br&gt;Specificity=90.0&lt;br&gt;Sensitivity=90.0&#39; ) fig.show() . . . . If you hover the mouse over the lines you can see the exact numbers. . As you can see, a positive or negative test does give more information than no test, but it doesn&#39;t quite give you certainty. . Story time - Part 2 . Let&#39;s circle back to our Dr. Antevy with his two positive tests and the two negative tests. . Prior to any tests, he was about 50% certain of having contracted COVID-19 based on his assesment of his symptoms, location, contact with other people, etc.. . Let&#39;s go through his test results to see what his posterior probability of having antibodies is. . #collapse_hide # Let&#39;s make a new function for multiple tests in a row def PposteriorM(Pprior, test_res): x = Pprior for tr, sn, sp in test_res: if tr == 1: x = (sn * x) / (sn * x + (1-sp) * (1-x)) elif tr == 0: x = (1-((sp * (1-x))/(1-(sn * x + (1-sp) * (1-x))))) return x . . Let&#39;s say these are the characteristics of the tests he used: . Test 1 and 2: Specificity = 0.90 | Sensitivity = 0.99 | . | Test 3 and 4: Specificity = 0.97 | Sensitivity = 0.95 | . | . So a highly sensitive first test followed by a rather good allround test, a bit more specific than the first. . #collapse_hide # Below is the prior probability of being infected: num=10000 Pprior = np.linspace((1/num),(num-1)/num,num=num) # Test characteristics test_results = [(1, 0.99, 0.90),(1, 0.99, 0.90),(0,0.95,0.97),(0,0.95,0.97)] # Graph the results fig = go.Figure(data=[ go.Scatter(name=&#39;1 - 1st positive test&#39;, x=100*Pprior, y=100*PposteriorM(Pprior, [test_results[0]])), go.Scatter(name=&#39;2 - 2nd positive test&#39;, x=100*Pprior, y=100*PposteriorM(Pprior, test_results[0:2])), go.Scatter(name=&#39;3 - 1st negative test&#39;, x=100*Pprior, y=100*PposteriorM(Pprior, test_results[0:3])), go.Scatter(name=&#39;4 - 2nd negative test&#39;, x=100*Pprior, y=100*PposteriorM(Pprior, test_results[0:4])) ]) fig.update_layout( xaxis_title = &#39;Prior probability of being infected&#39;, yaxis_title = &#39;Posterior probability of being infected given test results&#39; ) fig.show() . . . . So let&#39;s go through step-by-step: . Before any test, he was about 50% sure he contracted COVID-19 | After the 1st positive test, this goes up to 90.8% sure | After the 2nd positive test, up to 99.0% sure | But the 1st negative test drops it back to 83.5% | And the 2nd negative all the way down to 20.7% | . What if this was done on a random person in France for example, and all 4 tests were positive. . Then the prior would be the prevalence in France (0.2%) instead of 50%, and the step by step would be as follows: . Before any test, about 0.20% | After 1st positive: still only 1.9% chance of being seropositive | After 2nd positive test: only 16.4% chance of seropositive | After 3rd positive: 86% | And after 4th positive test 99.5% | . So it took about 4 positive tests for a random person in France to become confident enough to be seropositive. . Discussion . The results above strongly underline the need for clear testing protocols and clear understanding of the interpretation of test results. . Wtih a disease that can be so devastating as COVID-19, a few things should be kept in mind: . A high treshold should be used to hedge the risk a false positive | Multiple tests should be taken | Multiple tests with different characteristics (ideally at least one with high sensitivity, and one with high specificity) | .",
            "url": "https://jeffufpost.github.io/scattered-thoughts/covid-19/testing/serology/2020/04/12/on-testing.html",
            "relUrl": "/covid-19/testing/serology/2020/04/12/on-testing.html",
            "date": " ‚Ä¢ Apr 12, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "Epidemic modeling - Part 5",
            "content": ". Motivation for write-up . This is the 5th part of a multi-part series blog post on modeling in epidemiology. . The COVID-19 pandemic has brought a lot of attention to the study of epidemiology and more specifically to the various mathematical models that are used to inform public health policies. Everyone has been trying to understand the growth or slowing of new cases and trying to predict the necessary sanitary resources. This blog post attempts to explain the foundations for some of the most used models and enlighten the reader on two key points. . The 1st part of the blog series showed an epidemic could occur when $R_0 &gt; 1$ and that it was fully characerized by the average $ beta$ and the average $T_{Infectious}$. . We have also seen that the higher $R_0$, the faster and the higher the peak infectious will be. . The latest blog post however showed the importance of the distribution of $T_{Infectious}$ to simulate the SEIR model and how it impacted the spread of the disease and the peak of infectious individuals. Even with lower $R_0$ values, the infectious peak were higher when using Gamma or Weibull distributions for $T_{Infectious}$. . This 5th installment examines this discrepancy further. . #collapse_hide !pip install plotly==4.6.0 import pandas as pd import numpy as np import math import plotly.graph_objects as go import plotly.express as px from scipy.stats import expon from scipy.stats import gamma from scipy.stats import weibull_min from numpy.random import default_rng rng = default_rng() # Let&#39;s build a numerical solution def seir_model(init, parms, days): S_0, E_0, I_0, R_0 = init Epd, Ipd, Rpd = [0], [0], [0] S, E, I, R = [S_0], [E_0], [I_0], [R_0] dt=0.1 t = np.linspace(0,days,int(days/dt)) sigma, beta, gam = parms for _ in t[1:]: next_S = S[-1] - beta*S[-1]*I[-1]*dt Epd.append(beta*S[-1]*I[-1]*dt) next_E = E[-1] + (beta*S[-1]*I[-1] - sigma*E[-1])*dt Ipd.append(sigma*E[-1]*dt) next_I = I[-1] + (sigma*E[-1] - gam*I[-1])*dt Rpd.append(gam*I[-1]*dt) next_R = R[-1] + (gam*I[-1])*dt S.append(next_S) E.append(next_E) I.append(next_I) R.append(next_R) return np.stack([S, E, I, R, Epd, Ipd, Rpd]).T . . Requirement already satisfied: plotly==4.6.0 in /usr/local/lib/python3.6/dist-packages (4.6.0) Requirement already satisfied: retrying&gt;=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly==4.6.0) (1.3.3) Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from plotly==4.6.0) (1.12.0) . #collapse_hide # Need this new function for model below: def make_df(p,num_E, num_I, num_R): df = pd.DataFrame(np.full((p,1), &#39;S&#39;).T[0], columns=[&#39;State&#39;]) df[&#39;Day&#39;] = 0 tochange=df.loc[rng.choice(p, size=num_E+num_I+num_R, replace=False),&#39;State&#39;].index df.loc[tochange[0:num_E],&#39;State&#39;] = &#39;E&#39; df.loc[tochange[num_E:num_I+num_E],&#39;State&#39;] = &#39;I&#39; df.loc[tochange[num_E+num_I:num_E+num_I+num_R],&#39;State&#39;] = &#39;R&#39; return df . . #collapse_hide def seir_model_stoch(beta, p, num_E, num_I, num_R, days, T_Latent, T_Infectious): # Initialize population dataframe with data given by user df = make_df(p,num_E, num_I, num_R) # This variable is used to track daily value of beta if it varies over time xxbeta=np.array([],dtype=float) # Initialize the arrays to return # Below are numbers of S, E, I, R total S=np.array([],dtype=int) E=np.array([],dtype=int) I=np.array([],dtype=int) R=np.array([],dtype=int) # Below are the daily additions in S, E, I, R Spd=np.array([],dtype=int) Epd=np.array([],dtype=int) Ipd=np.array([],dtype=int) Rpd=np.array([],dtype=int) b=beta # Stochastic model so use random values to decide on progression rand = np.random.random(size=(p,days)) # Depending if you want exponential or gamma distribution for T_Latent if T_Latent == &#39;expon&#39;: EtoI = expon.rvs(loc=0,scale=5.2,size=p) else: EtoI = gamma.rvs(1.8,loc=0.9,scale=(5.2-1.8)/0.9,size=p) # Depending if you want exponential, gamma, or Weibull distribution for T_Infectious # Uses distributions found on blog part 3 if T_Infectious == &#39;expon&#39;: ItoR = expon.rvs(loc=0,scale=28.85,size=p) elif T_Infectious == &#39;gamma&#39;: ItoR = gamma.rvs(4,loc=3,scale=4.25,size=p) else: ItoR = weibull_min.rvs(2.3, loc=2, scale=20.11, size=p) # Iterate over every day the simulation is run for j in range(0,days-1): # Record daily beta values xxbeta=np.append(beta, b) # First we get the index of the individuals that will change state today: # Random number tells you which &#39;S&#39; have been exposed on this day StoE_index = df.loc[(df.State == &#39;S&#39;) &amp; (rand[:,j] &lt; b[j]*len(np.where(df.State==&#39;I&#39;)[0])/p)].index # For each row, if a person has been a certain number of days in E, they will go to I # This follows EtoI variable which is either exponential or gamma distributed according to above EtoI_index = df.loc[(df.State == &#39;E&#39;) &amp; (j-df.Day &gt;= EtoI)].index # Similaraly as above # For each row, if a person has been a certain number of days in I, they will go to R # This follows EtoI variable which is either exponential or gamma distributed according to above ItoR_index = df.loc[(df.State == &#39;I&#39;) &amp; (j-df.Day &gt;= ItoR)].index # Use indexes collected above to populate per day values Epd = np.append(Epd,len(StoE_index)) Ipd = np.append(Ipd,len(EtoI_index)) Rpd = np.append(Rpd,len(ItoR_index)) # Now we use the indexes collected above randomly to change the actual population dataframe to the new states df.loc[ItoR_index, &#39;State&#39;] = &#39;R&#39; df.loc[EtoI_index, &#39;State&#39;] = &#39;I&#39; df.loc[StoE_index, &#39;State&#39;] = &#39;E&#39; df.loc[ItoR_index, &#39;Day&#39;] = j df.loc[EtoI_index, &#39;Day&#39;] = j df.loc[StoE_index, &#39;Day&#39;] = j df.loc[ItoR_index, &#39;DayR&#39;] = j df.loc[EtoI_index, &#39;DayI&#39;] = j df.loc[StoE_index, &#39;DayE&#39;] = j # Append the S, E, I, and R arrays S=np.append(S,len(np.where(df.State==&#39;S&#39;)[0])) E=np.append(E,len(np.where(df.State==&#39;E&#39;)[0])) I=np.append(I,len(np.where(df.State==&#39;I&#39;)[0])) R=np.append(R,len(np.where(df.State==&#39;R&#39;)[0])) # Code below for control measures to reduce beta values # if ((I[-1] &gt; 1000) &amp; (Ipd[-1] &gt; 399)): # b = beta2 # elif ((I[-1] &gt; 1000) &amp; (Ipd[-1] &lt; 400)): # b = beta3 Epd[0]+=num_E Ipd[0]+=num_I Rpd[0]+=num_R return S,E,I,R, Epd, Ipd, Rpd, xxbeta, df . . Peak of infectious individuals . Let&#39;s first try to characterize when the peak of infectious indiviuals occurs in the SEIR model. . The peak of infectious individuals occurs when the number of individuals that recover per day ($R_{pd}$) becomes greater than the number of new infectious individuals per day ($I_{pd}$), i.e. when: $$R_{pd} geq I_{pd}$$ . Convolution and daily numbers . Mathematical derivation of $I_{pd}$: . In the stochastic model, the number of new infectious individuals per day is the sum of the daily new exposures per day of the previous days multiplied by the probability that they become infectious after so many days. . We write: $$I_{pd}[j] = sum_{n_L=0}^{M_L-1}h_L[n_L]~E_{pd}[j-n_L]$$ . Mathematically, this means $I_{pd}[j]$ is the result of convolution of $E_{pd}$ and an impulse response $h_L[n]$ where $h_L[n]$ describes the distribution of $T_{Latent}$, and we can write: $$I_{pd}[j] = h_L[j] circledast E_{pd}[j]$$ . From this derivation, we can see the $I_{pd}$ depends on the distribution of $T_{Latent}$ and $E_{pd}$ (the number of new exposures per day) of the previous days. . When initial conditions are the same, this means $T_{Infectious}$ has no impact on $I_{pd}$ and so the rate of new infectious individuals will look the same between the two models (exponential or gamma distributed $T_{Infectious}$). . Mathematical derivation of $R_{pd}$: . We can similarly describe $R_{pd}[j]$ as the result of convolution of $I_{pd}$ and an impulse response $h_I[n]$ where $h_I[n]$ describes the distribution of $T_{Infectious}$. . In other words: $$R_{pd}[j] = sum_{n_I=0}^{M_I-1}h_I[n_I]~I_{pd}[j-n_I] = h_I[j] circledast I_{pd}[j]$$ . When does the peak occur? . It occurs on day j where the threshold below is reached: $$R_{pd}[j] = I_{pd}[j]$$ $$ leftrightarrow sum_{n_I=0}^{M_I-1}h_I[n_I]~I_{pd}[j-n_I] = sum_{n_L=0}^{M_L-1}h_L[n_L]~E_{pd}[j-n_L]$$ . While this is complicated to solve analytically, we can look at the distribution of $T_{Infectious}$ and get some clues as to what might happen with different distributions. . $I_{pd}$ and $R_{pd}$ for $T_{Infectious} sim Exp( lambda)$ vs. $T_{Infectious} sim Weibull( lambda, k, gamma)$ . $T_{Infectious} sim Exp(28.85)$ vs. $T_{Infectious} sim Weibull(2.3, 20.11, 2)$ . Let&#39;s first have another look at the difference between these two distributions: . #collapse_hide locw=2 wk = 2.3 wl = (20-locw)/(math.log(2)**(1/wk)) loce=0 scalee=28.85-loce p=10000 df = pd.DataFrame({ &#39;Exponential&#39;: expon.rvs(loc=loce, scale=scalee,size=p), &#39;Weibull&#39;: weibull_min.rvs(wk, loc=locw, scale=wl,size=p) }) fig = px.histogram(df.stack().reset_index().rename(columns={&quot;level_1&quot;: &quot;Distribution&quot;}), x=0, color=&quot;Distribution&quot;, marginal=&#39;box&#39;) fig.update_layout( title={ &#39;text&#39;:&#39;Exponential vs. Weibull distributions&#39;, &#39;x&#39;:0.5, &#39;xanchor&#39;:&#39;center&#39; }, barmode=&#39;overlay&#39;, xaxis_title=&#39;Days&#39;, yaxis_title=&#39;Count&#39;, legend=dict( x=1, y=0, traceorder=&quot;normal&quot;, ) ) fig.show() . . . . Impact on $I_{pd}$ $R_{pd}$: . Let&#39;s see how the two distributions of $T_{Infectious}$ result in different curbs for $I_{pd}$ and $R_{pd}$. . #collapse_hide # Define parameters for stochastic model days = 200 p = 10000 num_E = 1 num_I = 0 num_R = 0 beta_stoch = 0.5*np.ones(days) # Run 2 stochastic simulations, 1 with exponential gamma, 1 with weibull gamma results_stoch0 = seir_model_stoch(beta_stoch, p, num_E, num_I, num_R, days, 1, &#39;expon&#39;) results_stoch1 = seir_model_stoch(beta_stoch, p, num_E, num_I, num_R, days, 1, 1) . . #collapse_hide fig = go.Figure(data=[ go.Scatter(name=&#39;Ipd_Exp&#39;, x=np.arange(len(results_stoch0[0])), y=results_stoch0[5], line={&#39;dash&#39;:&#39;dashdot&#39;, &#39;color&#39;:&#39;red&#39;}, legendgroup=&quot;stoch4&quot;), go.Scatter(name=&#39;Rpd_Exp&#39;, x=np.arange(len(results_stoch0[0])), y=results_stoch0[6], line={&#39;dash&#39;:&#39;dashdot&#39;, &#39;color&#39;:&#39;green&#39;}, legendgroup=&quot;stoch4&quot;), go.Scatter(name=&#39;Ipd_Weibull&#39;, x=np.arange(len(results_stoch1[0])), y=results_stoch1[5], line={&#39;dash&#39;:&#39;solid&#39;, &#39;color&#39;:&#39;red&#39;}, legendgroup=&quot;stoch3&quot;), go.Scatter(name=&#39;Rpd_Weibull&#39;, x=np.arange(len(results_stoch1[0])), y=results_stoch1[6], line={&#39;dash&#39;:&#39;solid&#39;, &#39;color&#39;:&#39;green&#39;}, legendgroup=&quot;stoch3&quot;) ]) fig.update_layout( xaxis_title = &#39;Day&#39;, yaxis_title = &#39;Count&#39;, title={ &#39;text&#39;:r&#39;$ text{Effect of Exponential vs. Weibull distributed } T_{Infectious} text{ on } I_{pd} text{ and } R_{pd}$&#39;, &#39;x&#39;:0.5, &#39;xanchor&#39;:&#39;center&#39; } ) fig.show() . . . . Analysis: . As discussed above, we can see here $I_{pd}$ are very similar between the two models. . However, there are two key takeaways from these graphs: . Rise of total infectious individuals: | The Exponential distribution leads to more recoveries early on as the $R_{pd}$ for the Exp distribution leads the $R_{pd}$ of the Weibull distribution by ~6 days in the earl recovery period. . Intuitively, we can thus understand that total infectious people will increase slower with the Eponential distribution than the Weibull distribution (since more people recover faster in the Exp model), and so the peak of infectious individuals will be earlier with the Weibull distribution. . Recoveries: | While the peak appears faster with a Weibull distribution, we also see that after the initial delay, the Weibull distribution leads to larger number of recoveries and so the total number of infectious individuals will tend to 0 much quicker than with the Exp distribution. . Discussion . While $R_0$ seemed to be a good measure of the spread of disease and a good predictor of the peak of infectious individuals in a population, we find here that the actual distribution of $T_{Infectious}$ plays a crucial role in detemining the dynamics of the SEIR model. . That is to say that while estimating $R_0$ is important in times of epidemics or pandemics, finding the actual distributions of $T_{Latent}$ and $T_{Infetious}$ are equally important in predicting the impact of the disease. .",
            "url": "https://jeffufpost.github.io/scattered-thoughts/modeling/seir/epidemiology/stochastic/covid-19/reproduction%20number/2020/04/01/diagnosing-R0-and-peak-infectious.html",
            "relUrl": "/modeling/seir/epidemiology/stochastic/covid-19/reproduction%20number/2020/04/01/diagnosing-R0-and-peak-infectious.html",
            "date": " ‚Ä¢ Apr 1, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "Epidemic modeling - Part 4",
            "content": ". Motivation for write-up . This is the 4th part of a multi-part series blog post on modeling in epidemiology. . The COVID-19 pandemic has brought a lot of attention to study of epidemiology and more specifically to the various mathematical models that are used to inform public health policies. Everyone has been trying to understand the growth or slowing of new cases and trying to predict the necessary sanitary resources. This blog post attempts to explain the foundations for some of the most used models and enlighten the reader on two key points. . After introducing the concepts of compartmentalization and disease dynamics in the first blog post, the second part looked at a deterministic numerical solution for the SEIR model discussed, and the effects of the parameters $ beta$, $ sigma$, and $ gamma$ in parts 1 and 2. . Part 3 made the argument that most models ignore individual-level disease dynamics in favor of averaging population-level $ sigma$ and $ gamma$ parameters and showed some big discrepancies between actual COVID-19 probability distributions for those parameters and those used in research. . This 4th part is where I build a numerical SEIR model that takes into account these probability distributions in order to tweak the model as close to COVID-19 data as possible. . Building a stochastic model . As opposed to the deterministic model from Part 2, this model is going to focus on individual level disease dynamics to model the disease propagation. . The basic idea of this model is to have a dataframe with the number of rows equal to the population size (each individual is a row) and two columns: . State column to describe the state of each individual (S, E, I, or R) | Day column to save the day of transition of the individual into that state | . However, the population-level rates of transmission still apply here i.e. a person goes from S &rarr; E following three points: . the number of contacts the person has per unit time (given by $r$) | the chance a given contact is with an I - infectious individual (the higher thenumber of I, the higher the chance) | the chance of an S contracting the disease from a contact with an I (given by $ rho$) | This is done stochastically. . Once a person becomes E, their progression is unique to them. This progression is calculated in advance for computational reason, but it allows to use the time ditributions we want. . #collapse_hide !pip install plotly==4.6.0 import pandas as pd import numpy as np import math import plotly.graph_objects as go import plotly.express as px from scipy.stats import expon from scipy.stats import gamma from scipy.stats import weibull_min from numpy.random import default_rng rng = default_rng() # Let&#39;s build a numerical solution def seir_model(init, parms, days): S_0, E_0, I_0, R_0 = init Epd, Ipd, Rpd = [0], [0], [0] S, E, I, R = [S_0], [E_0], [I_0], [R_0] dt=0.1 t = np.linspace(0,days,int(days/dt)) sigma, beta, gam = parms for _ in t[1:]: next_S = S[-1] - beta*S[-1]*I[-1]*dt Epd.append(beta*S[-1]*I[-1]*dt) next_E = E[-1] + (beta*S[-1]*I[-1] - sigma*E[-1])*dt Ipd.append(sigma*E[-1]*dt) next_I = I[-1] + (sigma*E[-1] - gam*I[-1])*dt Rpd.append(gam*I[-1]*dt) next_R = R[-1] + (gam*I[-1])*dt S.append(next_S) E.append(next_E) I.append(next_I) R.append(next_R) return np.stack([S, E, I, R, Epd, Ipd, Rpd]).T . . Collecting plotly==4.6.0 Downloading https://files.pythonhosted.org/packages/15/90/918bccb0ca60dc6d126d921e2c67126d75949f5da777e6b18c51fb12603d/plotly-4.6.0-py2.py3-none-any.whl (7.1MB) |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7.2MB 4.6MB/s Requirement already satisfied: retrying&gt;=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly==4.6.0) (1.3.3) Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from plotly==4.6.0) (1.12.0) Installing collected packages: plotly Found existing installation: plotly 4.4.1 Uninstalling plotly-4.4.1: Successfully uninstalled plotly-4.4.1 Successfully installed plotly-4.6.0 . Creating the initial population dataframe . Below is a function to create the initial population dataframe: . $p$ is the population number | $num_E$ is the number of people exposed on day 0 | $num_I$ is the number of infectious on day 0 | $num_R$ is the number of people recovered on day 0 | . #collapse_hide # Need this new function for model below: def make_df(p,num_E, num_I, num_R): df = pd.DataFrame(np.full((p,1), &#39;S&#39;).T[0], columns=[&#39;State&#39;]) df[&#39;Day&#39;] = 0 tochange=df.loc[rng.choice(p, size=num_E+num_I+num_R, replace=False),&#39;State&#39;].index df.loc[tochange[0:num_E],&#39;State&#39;] = &#39;E&#39; df.loc[tochange[num_E:num_I+num_E],&#39;State&#39;] = &#39;I&#39; df.loc[tochange[num_E+num_I:num_E+num_I+num_R],&#39;State&#39;] = &#39;R&#39; return df . . Building the model . #collapse_hide def seir_model_stoch(beta, p, num_E, num_I, num_R, days, T_Latent, T_Infectious): # Initialize population dataframe with data given by user df = make_df(p,num_E, num_I, num_R) # This variable is used to track daily value of beta if it varies over time xxbeta=np.array([],dtype=float) # Initialize the arrays to return # Below are numbers of S, E, I, R total S=np.array([],dtype=int) E=np.array([],dtype=int) I=np.array([],dtype=int) R=np.array([],dtype=int) # Below are the daily additions in S, E, I, R Spd=np.array([],dtype=int) Epd=np.array([],dtype=int) Ipd=np.array([],dtype=int) Rpd=np.array([],dtype=int) b=beta # Stochastic model so use random values to decide on progression rand = np.random.random(size=(p,days)) # Depending if you want exponential or gamma distribution for T_Latent if T_Latent == &#39;expon&#39;: EtoI = expon.rvs(loc=0,scale=5.2,size=p) else: EtoI = gamma.rvs(1.8,loc=0.9,scale=(5.2-1.8)/0.9,size=p) # Depending if you want exponential, gamma, or Weibull distribution for T_Infectious # Uses distributions found on blog part 3 if T_Infectious == &#39;expon&#39;: ItoR = expon.rvs(loc=0,scale=28.85,size=p) elif T_Infectious == &#39;gamma&#39;: ItoR = gamma.rvs(4,loc=3,scale=4.25,size=p) else: ItoR = weibull_min.rvs(2.3, loc=2, scale=20.11, size=p) # Iterate over every day the simulation is run for j in range(0,days-1): # Record daily beta values xxbeta=np.append(beta, b) # First we get the index of the individuals that will change state today: # Random number tells you which &#39;S&#39; have been exposed on this day StoE_index = df.loc[(df.State == &#39;S&#39;) &amp; (rand[:,j] &lt; b[j]*len(np.where(df.State==&#39;I&#39;)[0])/p)].index # For each row, if a person has been a certain number of days in E, they will go to I # This follows EtoI variable which is either exponential or gamma distributed according to above EtoI_index = df.loc[(df.State == &#39;E&#39;) &amp; (j-df.Day &gt;= EtoI)].index # Similaraly as above # For each row, if a person has been a certain number of days in I, they will go to R # This follows EtoI variable which is either exponential or gamma distributed according to above ItoR_index = df.loc[(df.State == &#39;I&#39;) &amp; (j-df.Day &gt;= ItoR)].index # Use indexes collected above to populate per day values Epd = np.append(Epd,len(StoE_index)) Ipd = np.append(Ipd,len(EtoI_index)) Rpd = np.append(Rpd,len(ItoR_index)) # Now we use the indexes collected above randomly to change the actual population dataframe to the new states df.iloc[ItoR_index] = [&#39;R&#39;, j] df.iloc[EtoI_index] = [&#39;I&#39;, j] df.iloc[StoE_index] = [&#39;E&#39;, j] # Append the S, E, I, and R arrays S=np.append(S,len(np.where(df.State==&#39;S&#39;)[0])) E=np.append(E,len(np.where(df.State==&#39;E&#39;)[0])) I=np.append(I,len(np.where(df.State==&#39;I&#39;)[0])) R=np.append(R,len(np.where(df.State==&#39;R&#39;)[0])) # Code below for control measures to reduce beta values # if ((I[-1] &gt; 1000) &amp; (Ipd[-1] &gt; 399)): # b = beta2 # elif ((I[-1] &gt; 1000) &amp; (Ipd[-1] &lt; 400)): # b = beta3 Epd[0]+=num_E Ipd[0]+=num_I Rpd[0]+=num_R return S,E,I,R, Epd, Ipd, Rpd, xxbeta . . Sanity check . Let&#39;s first make sure the stochastic model above gives similar result to the deterministic model previously used in part 2 if we use an exponential distribution for $T_{Latent}$ and $T_{Infectious}$. . E &rarr; I . So let&#39;s first set all individuals to exposed on day 0 and see the progression to I with exponential and gamma distributions. . #collapse_hide # Define parameters for stochastc model days = 20 p = 10000 num_E = 10000 num_I = 0 num_R = 0 beta_stoch = 0.5*np.ones(days) # Comparing with previous deterministic model init = 0, p, 0, 0 sigma = 1/5.2 # 1/5 --&gt; 5 days on average to go from E --&gt; I beta_det = 0.5 gam = 1/28.85 # 1/11 --&gt; 11 days on average to go from I --&gt; R parms = sigma, beta_det, gam # Run deterministic simulation results_avg = seir_model(init, parms, days) # Run stochastic simulation with exponential distribution results_stoch_exp = seir_model_stoch(beta_stoch, p, num_E, num_I, num_R, days, &#39;expon&#39;, &#39;expon&#39;) # Run stochastic simulation with gamma distribution results_stoch_gam = seir_model_stoch(beta_stoch, p, num_E, num_I, num_R, days, 1, &#39;expon&#39;) . . #collapse_hide fig = go.Figure(data=[ go.Scatter(name=&#39;Exponential&#39;, x=np.arange(len(results_stoch_exp[0])), y=100*(1-results_stoch_exp[1]/p), line={&#39;dash&#39;:&#39;dash&#39;, &#39;color&#39;:&#39;red&#39;}), go.Scatter(name=&#39;Gamma&#39;, x=np.arange(len(results_stoch_gam[0])), y=100*(1-results_stoch_gam[1]/p), line={&#39;dash&#39;:&#39;dash&#39;, &#39;color&#39;:&#39;green&#39;}), go.Scatter(name=&#39;Deterministic&#39;, x=np.linspace(0,days,days*10), y=100*(1-results_avg.T[1]/p), line={&#39;dash&#39;:&#39;dot&#39;, &#39;color&#39;:&#39;blue&#39;}), ]) fig.update_layout( title=&#39;Number of E moving to I over time when all population is exposed on day 0&#39;, xaxis_title=&#39;Days&#39;, yaxis_title=&#39;Percent of exposed having become infectious&#39;, legend=dict( x=1, y=1, traceorder=&quot;normal&quot;, ) ) fig.show() . . . . So we can see using the exponential distribution for $T_{Latent}$ in our stochastic model very closely resembles the deterministic model from part 2. . We can see using the gamma distribution forces the behaviour of individual-level disease progression also. . I &rarr; R . Now let&#39;s set all individuals to infectious on day 0 and see the progression to R with exponential, gamma, and Weibull distributions. . #collapse_hide # Define parameters for stochastc model days = 100 p = 10000 num_E = 0 num_I = 10000 num_R = 0 beta_stoch = 0.5*np.ones(days) # Comparing with previous average deterministic model init = 0, 0, p, 0 sigma = 1/5.2 # 1/5 --&gt; 5 days on average to go from E --&gt; I beta_det = 0.5 gam = 1/28.85 # 1/11 --&gt; 11 days on average to go from I --&gt; R parms = sigma, beta_det, gam # Run deterministic simulation results_avg = seir_model(init, parms, days) # Run stochastic simulation with exponential distribution results_stoch_exp = seir_model_stoch(beta_stoch, p, num_E, num_I, num_R, days, 1, &#39;expon&#39;) # Run stochastic simulation with gamma distribution results_stoch_gam = seir_model_stoch(beta_stoch, p, num_E, num_I, num_R, days, 1, &#39;gamma&#39;) # Run stochastic simulation with gamma distribution results_stoch_wei = seir_model_stoch(beta_stoch, p, num_E, num_I, num_R, days, 1, &#39;weibull&#39;) . . #collapse_hide fig = go.Figure(data=[ go.Scatter(name=&#39;Exponential&#39;, x=np.arange(len(results_stoch_exp[0])), y=100*(1-results_stoch_exp[2]/p), line={&#39;dash&#39;:&#39;dash&#39;, &#39;color&#39;:&#39;red&#39;}), go.Scatter(name=&#39;Gamma&#39;, x=np.arange(len(results_stoch_gam[0])), y=100*(1-results_stoch_gam[2]/p), line={&#39;dash&#39;:&#39;dash&#39;, &#39;color&#39;:&#39;green&#39;}), go.Scatter(name=&#39;Weibull&#39;, x=np.arange(len(results_stoch_wei[0])), y=100*(1-results_stoch_wei[2]/p), line={&#39;dash&#39;:&#39;dash&#39;, &#39;color&#39;:&#39;orange&#39;}), go.Scatter(name=&#39;Deterministic&#39;, x=np.linspace(0,days,days*10), y=100*(1-results_avg.T[2]/p), line={&#39;dash&#39;:&#39;dot&#39;, &#39;color&#39;:&#39;blue&#39;}), ]) fig.update_layout( title=&#39;Number of I moving to R over time when all population is infectious on day 0&#39;, xaxis_title=&#39;Days&#39;, yaxis_title=&#39;Percent of infectious having become recovered&#39;, legend=dict( x=1, y=1, traceorder=&quot;normal&quot;, ) ) fig.show() . . . . So we can see using the exponential distribution for $ gamma$ in our stochastic model very closely resembles the deterministic model from part 2. . We can see using the gamma or Weibull distributions forces the behaviour of individual-level disease progression also and results in a vastly different picture for progression from I &rarr; R. . Comparing deterministic with stochastic SEIR models . Now that we know our model works, let&#39;s quickly see the effect of stochasticity on the model. . We use the deterministic model from blog pat 2 as basis, and so the stochastic model here will use exponential distributions for $ sigma$ and $ gamma$. . #collapse_hide # Define parameters for stochastic model days = 200 p = 10000 num_E = 1 num_I = 0 num_R = 0 beta_stoch = 0.5*np.ones(days) # Define parameters for deterministic model init = 1-(num_E/p)-(num_I/p)-(num_R/p), num_E/p, num_I/p, num_R/p sigma = 1/5.2 # 1/5 --&gt; 5 days on average to go from E --&gt; I beta_det = 0.5 gam = 1/28.85 # 1/11 --&gt; 11 days on average to go from I --&gt; R parms = sigma, beta_det, gam # Run deterministic simulation results_avg = seir_model(init, parms, days) # Run 3 stochastic simulations results_stoch1 = seir_model_stoch(beta_stoch, p, num_E, num_I, num_R, days, &#39;expon&#39;, &#39;expon&#39;) results_stoch2 = seir_model_stoch(beta_stoch, p, num_E, num_I, num_R, days, &#39;expon&#39;, &#39;expon&#39;) results_stoch3 = seir_model_stoch(beta_stoch, p, num_E, num_I, num_R, days, &#39;expon&#39;, &#39;expon&#39;) . . #collapse_hide fig = go.Figure(data=[ go.Scatter(name=&#39;S_det&#39;, x=np.linspace(0,days,days*10), y=results_avg.T[0], line={&#39;dash&#39;:&#39;solid&#39;, &#39;color&#39;:&#39;blue&#39;}, legendgroup=&quot;det&quot;), go.Scatter(name=&#39;E_det&#39;, x=np.linspace(0,days,days*10), y=results_avg.T[1], line={&#39;dash&#39;:&#39;solid&#39;, &#39;color&#39;:&#39;yellow&#39;}, legendgroup=&quot;det&quot;), go.Scatter(name=&#39;I_det&#39;, x=np.linspace(0,days,days*10), y=results_avg.T[2], line={&#39;dash&#39;:&#39;solid&#39;, &#39;color&#39;:&#39;red&#39;}, legendgroup=&quot;det&quot;), go.Scatter(name=&#39;R_det&#39;, x=np.linspace(0,days,days*10), y=results_avg.T[3], line={&#39;dash&#39;:&#39;solid&#39;, &#39;color&#39;:&#39;green&#39;}, legendgroup=&quot;det&quot;), go.Scatter(name=&#39;S_stoch1&#39;, x=np.arange(len(results_stoch1[0])), y=results_stoch1[0]/p, line={&#39;dash&#39;:&#39;dot&#39;, &#39;color&#39;:&#39;blue&#39;}, legendgroup=&quot;stoch1&quot;), go.Scatter(name=&#39;E_stoch1&#39;, x=np.arange(len(results_stoch1[0])), y=results_stoch1[1]/p, line={&#39;dash&#39;:&#39;dot&#39;,&#39;color&#39;:&#39;yellow&#39;}, legendgroup=&quot;stoch1&quot;), go.Scatter(name=&#39;I_stoch1&#39;, x=np.arange(len(results_stoch1[0])), y=results_stoch1[2]/p, line={&#39;dash&#39;:&#39;dot&#39;, &#39;color&#39;:&#39;red&#39;}, legendgroup=&quot;stoch1&quot;), go.Scatter(name=&#39;R_stoch1&#39;, x=np.arange(len(results_stoch1[0])), y=results_stoch1[3]/p, line={&#39;dash&#39;:&#39;dot&#39;, &#39;color&#39;:&#39;green&#39;}, legendgroup=&quot;stoch1&quot;), go.Scatter(name=&#39;S_stoch2&#39;, x=np.arange(len(results_stoch2[0])), y=results_stoch2[0]/p, line={&#39;dash&#39;:&#39;dot&#39;, &#39;color&#39;:&#39;blue&#39;}, legendgroup=&quot;stoch2&quot;), go.Scatter(name=&#39;E_stoch2&#39;, x=np.arange(len(results_stoch2[0])), y=results_stoch2[1]/p, line={&#39;dash&#39;:&#39;dot&#39;,&#39;color&#39;:&#39;yellow&#39;}, legendgroup=&quot;stoch2&quot;), go.Scatter(name=&#39;I_stoch2&#39;, x=np.arange(len(results_stoch2[0])), y=results_stoch2[2]/p, line={&#39;dash&#39;:&#39;dot&#39;, &#39;color&#39;:&#39;red&#39;}, legendgroup=&quot;stoch2&quot;), go.Scatter(name=&#39;R_stoch2&#39;, x=np.arange(len(results_stoch2[0])), y=results_stoch2[3]/p, line={&#39;dash&#39;:&#39;dot&#39;, &#39;color&#39;:&#39;green&#39;}, legendgroup=&quot;stoch2&quot;), go.Scatter(name=&#39;S_stoch3&#39;, x=np.arange(len(results_stoch3[0])), y=results_stoch3[0]/p, line={&#39;dash&#39;:&#39;dot&#39;, &#39;color&#39;:&#39;blue&#39;}, legendgroup=&quot;stoch3&quot;), go.Scatter(name=&#39;E_stoch3&#39;, x=np.arange(len(results_stoch3[0])), y=results_stoch3[1]/p, line={&#39;dash&#39;:&#39;dot&#39;, &#39;color&#39;:&#39;yellow&#39;}, legendgroup=&quot;stoch3&quot;), go.Scatter(name=&#39;I_stoch3&#39;, x=np.arange(len(results_stoch3[0])), y=results_stoch3[2]/p, line={&#39;dash&#39;:&#39;dot&#39;, &#39;color&#39;:&#39;red&#39;}, legendgroup=&quot;stoch3&quot;), go.Scatter(name=&#39;R_stoch3&#39;, x=np.arange(len(results_stoch3[0])), y=results_stoch3[3]/p, line={&#39;dash&#39;:&#39;dot&#39;, &#39;color&#39;:&#39;green&#39;}, legendgroup=&quot;stoch3&quot;) ]) fig.update_layout( xaxis_title = &#39;Day&#39;, yaxis_title = &#39;Proportion of population&#39;, title={ &#39;text&#39;:r&#39;$ text{Effect of stochasticity on Deterministic SEIR model}$&#39;, &#39;x&#39;:0.5, &#39;xanchor&#39;:&#39;center&#39; } ) fig.show() . . . . We can see very similar curves. The stochasticity appears to influence the time at which the epidemic starts but not the shape of the curves. . $ sigma$: exponential or gamma distribution . In this section we want to examine the effect of a gamma distribution has on the SEIR model (we keep exponential distribution for $ gamma$). . #collapse_hide # Define parameters for stochastic model days = 200 p = 10000 num_E = 1 num_I = 0 num_R = 0 beta_stoch = 0.5*np.ones(days) # Run 4 stochastic simulations, 2 with exponential sigma, 2 with gamma sigma results_stoch0 = seir_model_stoch(beta_stoch, p, num_E, num_I, num_R, days, &#39;expon&#39;, &#39;expon&#39;) results_stoch1 = seir_model_stoch(beta_stoch, p, num_E, num_I, num_R, days, &#39;expon&#39;, &#39;expon&#39;) results_stoch2 = seir_model_stoch(beta_stoch, p, num_E, num_I, num_R, days, 1, &#39;expon&#39;) results_stoch3 = seir_model_stoch(beta_stoch, p, num_E, num_I, num_R, days, 1, &#39;expon&#39;) . . #collapse_hide fig = go.Figure(data=[ go.Scatter(name=&#39;S_stoch_exp1&#39;, x=np.arange(len(results_stoch0[0])), y=results_stoch0[0]/p, line={&#39;dash&#39;:&#39;solid&#39;, &#39;color&#39;:&#39;blue&#39;}, legendgroup=&quot;det&quot;), go.Scatter(name=&#39;E_stoch_exp1&#39;, x=np.arange(len(results_stoch0[0])), y=results_stoch0[1]/p, line={&#39;dash&#39;:&#39;solid&#39;, &#39;color&#39;:&#39;yellow&#39;}, legendgroup=&quot;det&quot;), go.Scatter(name=&#39;I_stoch_exp1&#39;, x=np.arange(len(results_stoch0[0])), y=results_stoch0[2]/p, line={&#39;dash&#39;:&#39;solid&#39;, &#39;color&#39;:&#39;red&#39;}, legendgroup=&quot;det&quot;), go.Scatter(name=&#39;R_stoch_exp1&#39;, x=np.arange(len(results_stoch0[0])), y=results_stoch0[3]/p, line={&#39;dash&#39;:&#39;solid&#39;, &#39;color&#39;:&#39;green&#39;}, legendgroup=&quot;det&quot;), go.Scatter(name=&#39;S_stoch_exp2&#39;, x=np.arange(len(results_stoch1[0])), y=results_stoch1[0]/p, line={&#39;dash&#39;:&#39;solid&#39;, &#39;color&#39;:&#39;blue&#39;}, legendgroup=&quot;stoch1&quot;), go.Scatter(name=&#39;E_stoch_exp2&#39;, x=np.arange(len(results_stoch1[0])), y=results_stoch1[1]/p, line={&#39;dash&#39;:&#39;solid&#39;,&#39;color&#39;:&#39;yellow&#39;}, legendgroup=&quot;stoch1&quot;), go.Scatter(name=&#39;I_stoch_exp2&#39;, x=np.arange(len(results_stoch1[0])), y=results_stoch1[2]/p, line={&#39;dash&#39;:&#39;solid&#39;, &#39;color&#39;:&#39;red&#39;}, legendgroup=&quot;stoch1&quot;), go.Scatter(name=&#39;R_stoch_exp2&#39;, x=np.arange(len(results_stoch1[0])), y=results_stoch1[3]/p, line={&#39;dash&#39;:&#39;solid&#39;, &#39;color&#39;:&#39;green&#39;}, legendgroup=&quot;stoch1&quot;), go.Scatter(name=&#39;S_stoch_gam1&#39;, x=np.arange(len(results_stoch2[0])), y=results_stoch2[0]/p, line={&#39;dash&#39;:&#39;dot&#39;, &#39;color&#39;:&#39;blue&#39;}, legendgroup=&quot;stoch2&quot;), go.Scatter(name=&#39;E_stoch_gam1&#39;, x=np.arange(len(results_stoch2[0])), y=results_stoch2[1]/p, line={&#39;dash&#39;:&#39;dot&#39;,&#39;color&#39;:&#39;yellow&#39;}, legendgroup=&quot;stoch2&quot;), go.Scatter(name=&#39;I_stoch_gam1&#39;, x=np.arange(len(results_stoch2[0])), y=results_stoch2[2]/p, line={&#39;dash&#39;:&#39;dot&#39;, &#39;color&#39;:&#39;red&#39;}, legendgroup=&quot;stoch2&quot;), go.Scatter(name=&#39;R_stoch_gam1&#39;, x=np.arange(len(results_stoch2[0])), y=results_stoch2[3]/p, line={&#39;dash&#39;:&#39;dot&#39;, &#39;color&#39;:&#39;green&#39;}, legendgroup=&quot;stoch2&quot;), go.Scatter(name=&#39;S_stoch_gam2&#39;, x=np.arange(len(results_stoch3[0])), y=results_stoch3[0]/p, line={&#39;dash&#39;:&#39;dot&#39;, &#39;color&#39;:&#39;blue&#39;}, legendgroup=&quot;stoch3&quot;), go.Scatter(name=&#39;E_stoch_gam2&#39;, x=np.arange(len(results_stoch3[0])), y=results_stoch3[1]/p, line={&#39;dash&#39;:&#39;dot&#39;, &#39;color&#39;:&#39;yellow&#39;}, legendgroup=&quot;stoch3&quot;), go.Scatter(name=&#39;I_stoch_gam2&#39;, x=np.arange(len(results_stoch3[0])), y=results_stoch3[2]/p, line={&#39;dash&#39;:&#39;dot&#39;, &#39;color&#39;:&#39;red&#39;}, legendgroup=&quot;stoch3&quot;), go.Scatter(name=&#39;R_stoch_gam2&#39;, x=np.arange(len(results_stoch3[0])), y=results_stoch3[3]/p, line={&#39;dash&#39;:&#39;dot&#39;, &#39;color&#39;:&#39;green&#39;}, legendgroup=&quot;stoch3&quot;) ]) fig.update_layout( xaxis_title = &#39;Day&#39;, yaxis_title = &#39;Proportion of population&#39;, title={ &#39;text&#39;:r&#39;$ text{Effect of gamma vs. exponential distributed } sigma text{ on SEIR model}$&#39;, &#39;x&#39;:0.5, &#39;xanchor&#39;:&#39;center&#39; } ) fig.show() . . . . As you can see here, it is difficult to tell how much the gamma distributed $ sigma$ differs from the exponential distributed model (other than just timing). . The infectious peak might be a little lower and delayed a bit with gama distribution, but it is hard to tell for sure from this. . The peak of exposed individuals seems to be a bit higher and delayed with gamma distribution versus exponential distribution. . $ gamma$: exponential, gamma, or Weibull distribution . In this section we want to examine the effect of having $T_{Infectious}$ be gamma or Weibull distribution on the SEIR model. . Exponential vs. Gamma . #collapse_hide # Define parameters for stochastic model days = 200 p = 10000 num_E = 1 num_I = 0 num_R = 0 beta_stoch = 0.5*np.ones(days) # Run 4 stochastic simulations, 2 with exponential sigma, 2 with gamma sigma results_stoch0 = seir_model_stoch(beta_stoch, p, num_E, num_I, num_R, days, 1, &#39;expon&#39;) results_stoch1 = seir_model_stoch(beta_stoch, p, num_E, num_I, num_R, days, 1, &#39;expon&#39;) results_stoch2 = seir_model_stoch(beta_stoch, p, num_E, num_I, num_R, days, 1, &#39;gamma&#39;) results_stoch3 = seir_model_stoch(beta_stoch, p, num_E, num_I, num_R, days, 1, &#39;gamma&#39;) . . #collapse_hide fig = go.Figure(data=[ go.Scatter(name=&#39;S_stoch_exp1&#39;, x=np.arange(len(results_stoch0[0])), y=results_stoch0[0]/p, line={&#39;dash&#39;:&#39;solid&#39;, &#39;color&#39;:&#39;blue&#39;}, legendgroup=&quot;det&quot;), go.Scatter(name=&#39;E_stoch_exp1&#39;, x=np.arange(len(results_stoch0[0])), y=results_stoch0[1]/p, line={&#39;dash&#39;:&#39;solid&#39;, &#39;color&#39;:&#39;yellow&#39;}, legendgroup=&quot;det&quot;), go.Scatter(name=&#39;I_stoch_exp1&#39;, x=np.arange(len(results_stoch0[0])), y=results_stoch0[2]/p, line={&#39;dash&#39;:&#39;solid&#39;, &#39;color&#39;:&#39;red&#39;}, legendgroup=&quot;det&quot;), go.Scatter(name=&#39;R_stoch_exp1&#39;, x=np.arange(len(results_stoch0[0])), y=results_stoch0[3]/p, line={&#39;dash&#39;:&#39;solid&#39;, &#39;color&#39;:&#39;green&#39;}, legendgroup=&quot;det&quot;), go.Scatter(name=&#39;S_stoch_exp2&#39;, x=np.arange(len(results_stoch1[0])), y=results_stoch1[0]/p, line={&#39;dash&#39;:&#39;solid&#39;, &#39;color&#39;:&#39;blue&#39;}, legendgroup=&quot;stoch1&quot;), go.Scatter(name=&#39;E_stoch_exp2&#39;, x=np.arange(len(results_stoch1[0])), y=results_stoch1[1]/p, line={&#39;dash&#39;:&#39;solid&#39;,&#39;color&#39;:&#39;yellow&#39;}, legendgroup=&quot;stoch1&quot;), go.Scatter(name=&#39;I_stoch_exp2&#39;, x=np.arange(len(results_stoch1[0])), y=results_stoch1[2]/p, line={&#39;dash&#39;:&#39;solid&#39;, &#39;color&#39;:&#39;red&#39;}, legendgroup=&quot;stoch1&quot;), go.Scatter(name=&#39;R_stoch_exp2&#39;, x=np.arange(len(results_stoch1[0])), y=results_stoch1[3]/p, line={&#39;dash&#39;:&#39;solid&#39;, &#39;color&#39;:&#39;green&#39;}, legendgroup=&quot;stoch1&quot;), go.Scatter(name=&#39;S_stoch_gam1&#39;, x=np.arange(len(results_stoch2[0])), y=results_stoch2[0]/p, line={&#39;dash&#39;:&#39;dot&#39;, &#39;color&#39;:&#39;blue&#39;}, legendgroup=&quot;stoch2&quot;), go.Scatter(name=&#39;E_stoch_gam1&#39;, x=np.arange(len(results_stoch2[0])), y=results_stoch2[1]/p, line={&#39;dash&#39;:&#39;dot&#39;,&#39;color&#39;:&#39;yellow&#39;}, legendgroup=&quot;stoch2&quot;), go.Scatter(name=&#39;I_stoch_gam1&#39;, x=np.arange(len(results_stoch2[0])), y=results_stoch2[2]/p, line={&#39;dash&#39;:&#39;dot&#39;, &#39;color&#39;:&#39;red&#39;}, legendgroup=&quot;stoch2&quot;), go.Scatter(name=&#39;R_stoch_gam1&#39;, x=np.arange(len(results_stoch2[0])), y=results_stoch2[3]/p, line={&#39;dash&#39;:&#39;dot&#39;, &#39;color&#39;:&#39;green&#39;}, legendgroup=&quot;stoch2&quot;), go.Scatter(name=&#39;S_stoch_gam2&#39;, x=np.arange(len(results_stoch3[0])), y=results_stoch3[0]/p, line={&#39;dash&#39;:&#39;dot&#39;, &#39;color&#39;:&#39;blue&#39;}, legendgroup=&quot;stoch3&quot;), go.Scatter(name=&#39;E_stoch_gam2&#39;, x=np.arange(len(results_stoch3[0])), y=results_stoch3[1]/p, line={&#39;dash&#39;:&#39;dot&#39;, &#39;color&#39;:&#39;yellow&#39;}, legendgroup=&quot;stoch3&quot;), go.Scatter(name=&#39;I_stoch_gam2&#39;, x=np.arange(len(results_stoch3[0])), y=results_stoch3[2]/p, line={&#39;dash&#39;:&#39;dot&#39;, &#39;color&#39;:&#39;red&#39;}, legendgroup=&quot;stoch3&quot;), go.Scatter(name=&#39;R_stoch_gam2&#39;, x=np.arange(len(results_stoch3[0])), y=results_stoch3[3]/p, line={&#39;dash&#39;:&#39;dot&#39;, &#39;color&#39;:&#39;green&#39;}, legendgroup=&quot;stoch3&quot;) ]) fig.update_layout( xaxis_title = &#39;Day&#39;, yaxis_title = &#39;Proportion of population&#39;, title={ &#39;text&#39;:r&#39;$ text{Effect of gamma vs. exponential distributed } gamma text{ on SEIR model}$&#39;, &#39;x&#39;:0.5, &#39;xanchor&#39;:&#39;center&#39; } ) fig.show() . . . . As you can see here, it is a lot easier to differentiate between the two. . A gamma distributed $ gamma$ results in a higher peak of infectious people and underlines how using the usual deterministic models can vastly underestimate peak infectious people. . Gamma vs. Weibull . #collapse_hide # Define parameters for stochastic model days = 200 p = 10000 num_E = 1 num_I = 0 num_R = 0 beta_stoch = 0.5*np.ones(days) # Run 4 stochastic simulations, 2 with exponential sigma, 2 with gamma sigma results_stoch0 = seir_model_stoch(beta_stoch, p, num_E, num_I, num_R, days, 1, &#39;weibull&#39;) results_stoch1 = seir_model_stoch(beta_stoch, p, num_E, num_I, num_R, days, 1, &#39;weibull&#39;) results_stoch2 = seir_model_stoch(beta_stoch, p, num_E, num_I, num_R, days, 1, &#39;gamma&#39;) results_stoch3 = seir_model_stoch(beta_stoch, p, num_E, num_I, num_R, days, 1, &#39;gamma&#39;) . . #collapse_hide fig = go.Figure(data=[ go.Scatter(name=&#39;S_stoch_wei1&#39;, x=np.arange(len(results_stoch0[0])), y=results_stoch0[0]/p, line={&#39;dash&#39;:&#39;solid&#39;, &#39;color&#39;:&#39;blue&#39;}, legendgroup=&quot;det&quot;), go.Scatter(name=&#39;E_stoch_wei1&#39;, x=np.arange(len(results_stoch0[0])), y=results_stoch0[1]/p, line={&#39;dash&#39;:&#39;solid&#39;, &#39;color&#39;:&#39;yellow&#39;}, legendgroup=&quot;det&quot;), go.Scatter(name=&#39;I_stoch_wei1&#39;, x=np.arange(len(results_stoch0[0])), y=results_stoch0[2]/p, line={&#39;dash&#39;:&#39;solid&#39;, &#39;color&#39;:&#39;red&#39;}, legendgroup=&quot;det&quot;), go.Scatter(name=&#39;R_stoch_wei1&#39;, x=np.arange(len(results_stoch0[0])), y=results_stoch0[3]/p, line={&#39;dash&#39;:&#39;solid&#39;, &#39;color&#39;:&#39;green&#39;}, legendgroup=&quot;det&quot;), go.Scatter(name=&#39;S_stoch_wei2&#39;, x=np.arange(len(results_stoch1[0])), y=results_stoch1[0]/p, line={&#39;dash&#39;:&#39;solid&#39;, &#39;color&#39;:&#39;blue&#39;}, legendgroup=&quot;stoch1&quot;), go.Scatter(name=&#39;E_stoch_wei2&#39;, x=np.arange(len(results_stoch1[0])), y=results_stoch1[1]/p, line={&#39;dash&#39;:&#39;solid&#39;,&#39;color&#39;:&#39;yellow&#39;}, legendgroup=&quot;stoch1&quot;), go.Scatter(name=&#39;I_stoch_wei2&#39;, x=np.arange(len(results_stoch1[0])), y=results_stoch1[2]/p, line={&#39;dash&#39;:&#39;solid&#39;, &#39;color&#39;:&#39;red&#39;}, legendgroup=&quot;stoch1&quot;), go.Scatter(name=&#39;R_stoch_wei2&#39;, x=np.arange(len(results_stoch1[0])), y=results_stoch1[3]/p, line={&#39;dash&#39;:&#39;solid&#39;, &#39;color&#39;:&#39;green&#39;}, legendgroup=&quot;stoch1&quot;), go.Scatter(name=&#39;S_stoch_gam1&#39;, x=np.arange(len(results_stoch2[0])), y=results_stoch2[0]/p, line={&#39;dash&#39;:&#39;dot&#39;, &#39;color&#39;:&#39;blue&#39;}, legendgroup=&quot;stoch2&quot;), go.Scatter(name=&#39;E_stoch_gam1&#39;, x=np.arange(len(results_stoch2[0])), y=results_stoch2[1]/p, line={&#39;dash&#39;:&#39;dot&#39;,&#39;color&#39;:&#39;yellow&#39;}, legendgroup=&quot;stoch2&quot;), go.Scatter(name=&#39;I_stoch_gam1&#39;, x=np.arange(len(results_stoch2[0])), y=results_stoch2[2]/p, line={&#39;dash&#39;:&#39;dot&#39;, &#39;color&#39;:&#39;red&#39;}, legendgroup=&quot;stoch2&quot;), go.Scatter(name=&#39;R_stoch_gam1&#39;, x=np.arange(len(results_stoch2[0])), y=results_stoch2[3]/p, line={&#39;dash&#39;:&#39;dot&#39;, &#39;color&#39;:&#39;green&#39;}, legendgroup=&quot;stoch2&quot;), go.Scatter(name=&#39;S_stoch_gam2&#39;, x=np.arange(len(results_stoch3[0])), y=results_stoch3[0]/p, line={&#39;dash&#39;:&#39;dot&#39;, &#39;color&#39;:&#39;blue&#39;}, legendgroup=&quot;stoch3&quot;), go.Scatter(name=&#39;E_stoch_gam2&#39;, x=np.arange(len(results_stoch3[0])), y=results_stoch3[1]/p, line={&#39;dash&#39;:&#39;dot&#39;, &#39;color&#39;:&#39;yellow&#39;}, legendgroup=&quot;stoch3&quot;), go.Scatter(name=&#39;I_stoch_gam2&#39;, x=np.arange(len(results_stoch3[0])), y=results_stoch3[2]/p, line={&#39;dash&#39;:&#39;dot&#39;, &#39;color&#39;:&#39;red&#39;}, legendgroup=&quot;stoch3&quot;), go.Scatter(name=&#39;R_stoch_gam2&#39;, x=np.arange(len(results_stoch3[0])), y=results_stoch3[3]/p, line={&#39;dash&#39;:&#39;dot&#39;, &#39;color&#39;:&#39;green&#39;}, legendgroup=&quot;stoch3&quot;) ]) fig.update_layout( xaxis_title = &#39;Day&#39;, yaxis_title = &#39;Proportion of population&#39;, title={ &#39;text&#39;:r&#39;$ text{Effect of Weibull vs. gamma distributed } gamma text{ on SEIR model}$&#39;, &#39;x&#39;:0.5, &#39;xanchor&#39;:&#39;center&#39; } ) fig.show() . . . . Overall both the gamma and Weibull distributions were very close to the actual distribution for COVID-19 $T_{Infectious}$ so it makes sense that the simulations results in similar curbs here. . Impact of distribution of $T_{Infectious}$ on Infectious Peak . In the plots above we can see the peak of infectious individuals is higher in the simulations done with Gamma or Weibull distributions than in those done with the exponential distribution. . Note we have not changed anything for $ beta$ and in the simulations above we have the following: . Exponential distribution: $$E[T_{Infectious}] = 28.85 days$$ $$R_0 = beta * E[T_{Infectious}] = 14.43$$ | Gamma distribution: $$E[T_{Infectious}] = 20.05 days$$ $$R_0 = beta * E[T_{Infectious}] = 10.03$$ | Weibull distribution: $$E[T_{Infectious}] = 20.77 days$$ $$R_0 = beta * E[T_{Infectious}] = 10.39$$ | . So while we have a higher $R_0$ when using the exonential distribution for $T_{Infectious}$, the peak of infectious individuals is lower than in the simulations using gamma and Weibull distributions with lower $R_0$. . We had previously seen that increasing $R_0$ resulted in high infectious peaks, but this is only true when comparing similar distributions. . Discussion . We can see the actual distribution of $ sigma$ and $ gamma$ carry importance in the resulting SEIR models. . $R_0$ . In part 1 we saw that $R_0$ was fully characterized by $ beta$ and $ gamma$ in the sense that $$R_0 = frac{ beta}{ gamma}$$ . We can clearly see here however that $R_0$ is not a good enough measure the indicate peak infectious individuals - which is closely related to the peak number of sick individuals which in turn determines required sanitary resources. . The actual distribution of $T_{Infectious}$ mus tbe taken into account to estimate true values of peaks. . Further questions . A couple questions are left to be answered: . How can we control the spread of an epidemic? | How can we evaluate $ beta$ from the data collected on a population level? | . See further blog posts. .",
            "url": "https://jeffufpost.github.io/scattered-thoughts/probability%20distributions/modeling/seir/epidemiology/stochastic/covid-19/2020/03/31/stochastic_model.html",
            "relUrl": "/probability%20distributions/modeling/seir/epidemiology/stochastic/covid-19/2020/03/31/stochastic_model.html",
            "date": " ‚Ä¢ Mar 31, 2020"
        }
        
    
  
    
        ,"post4": {
            "title": "Epidemic modeling - Part 3",
            "content": ". Motivation for write-up . This is the 3rd part of a multi-part series blog post on modeling in epidemiology. . The COVID-19 pandemic has brought a lot of attention to study of epidemiology and more specifically to the various mathematical models that are used to inform public health policies. Everyone has been trying to understand the growth or slowing of new cases and trying to predict the necessary sanitary resources. This blog post attempts to explain the foundations for some of the most used models and enlighten the reader on two key points. . After introducing the concepts of compartmentalization and disease dynamics in the first blog post, the second part looked at a deterministic numerical solution for the SEIR model discussed, and the effects of the parameters $ beta$, $ sigma$, and $ gamma$. . While arguments can be made that the compartments themselves don&#39;t reflect the reality of COVID-19, this is not the point of this discussion; I want to focus on the idea that the population level dynamics forget about the individual progression of the disease. . With this mind, this third part is going to discuss the problems that arise when averaging the latent period ($ frac{1}{ sigma}$) and infectious period ($ frac{1}{ gamma}$) on the simulations. . Let&#39;s have a look at the individual progression of disease to understand what is wrong. . Implications of deterministic model . Latent period $= T_{Latent} = frac{1}{ sigma}$ . Using the numerical model in part 2 and in order to see the distribution of E &rarr; I, we set the initial number of E to be the same as the population, and plot the number of E over time as below: . #collapse_hide # Define parameters days = 30 N = 10000 init = 0, N, 0, 0 sigma = 1/5.2 beta = 0.5 gam = 1/28.85 parms = sigma, beta, gam # Plot simulation fig = go.Figure(data=[ go.Scatter(name=&#39;E to I&#39;, x=np.linspace(0,days,days*10), y=100*(1-seir_model(init, parms, days).T[1]/N)), go.Scatter(name=&#39;$ text{Exponential distribution with} Scale = frac{1}{ sigma}$&#39;, x=np.arange(days), y=100*expon.cdf(np.arange(days),loc=0,scale=1/sigma)) ]) fig.update_layout( title=&#39;Number of E moving to I over time when all population is exposed on day 0&#39;, xaxis_title=&#39;Days&#39;, yaxis_title=&#39;Percent of exposed having become infectious&#39;, legend=dict( x=0.6, y=0, traceorder=&quot;normal&quot;, ) ) fig.show() . . . . The plot above confirms the numerical model from part 2 assumes people go from E &rarr; I according to the exponential distribution. . Infectious period $= T_{Infectious} = frac{1}{ gamma}$ . The same discussion above applies for the time from I &rarr; R here. . From the discussion above, we know the numerical model in part 2 approximates the time from I &rarr; R as an exponential distribution. . Let&#39;s verifiy this in the plot below: . #collapse_hide # Define parameters days = 100 N = 10000 init = 0, 0, N, 0 sigma = 1/5.2 # 1/5 --&gt; 5 days on average to go from E --&gt; I beta = 0.5 gam = 1/28.85 # 1/11 --&gt; 11 days on average to go from I --&gt; R parms = sigma, beta, gam # Plot simulation fig = go.Figure(data=[ go.Scatter(name=&#39;I to R&#39;, x=np.linspace(0,days,days*10), y=100*(1-seir_model(init, parms, days).T[2]/N)), go.Scatter(name=&#39;$ text{Exponential distribution with} Scale = frac{1}{ gamma}$&#39;, x=np.arange(days), y=100*expon.cdf(np.arange(days),loc=0,scale=1/gam)) ]) fig.update_layout( title=&#39;Number of I moving to R over time when all population is infectious on day 0&#39;, xaxis_title=&#39;Days&#39;, yaxis_title=&#39;Percent of infectious having become recovered&#39;, legend=dict( x=0.6, y=0, traceorder=&quot;normal&quot;, ) ) fig.show() . . . . The plot above confirms the numerical model from part 2 assumes people go from I &rarr; R according to the exponential distribution. . Comparing exponential distribution to COVID-19 data . As we have seen above, this deterministic model implies $T_{Latent}$ and $T_{Infectious}$ are exponentially distributed and we know the exponential distribution is uniquely characterized by its scale where: $$scale = frac{1}{mean}$$ . Latent period . For COVID-19, as we have seen in part 2 of the blog, research has shown the following for $T_{Latent}$: . mean = 5.2 days | range is [2,14] days | 95th percentile is 12.5 days | . Assuming an exponential distribution, however, we would obtain the following: . $mean = frac{1}{scale} = 5.2 days$ | 95th percentile would be 16 days | After the first day in state E, 18% would move into the state I (the fastest in real-world data was 2 days so this is not possible) | . While we can adjust to scale to fit the real-world mean, the distribution does not match the real-world data. . Infectious period . Similarly as above, for COVID-19 we have seen research has shown the following for $T_{Infectious}$: . median = 20 days | range is [8,37] days | . Assuming an exponential distribution, however, we would obtain the following: . $mean = frac{median}{ ln2} = frac{20}{ ln2} = 28.85 days$ | 95th percentile would be 87 days, while we&#39;d likely want it to be around 37 days | After the first day in state I, 18% would move into the state R (the fastest in real-world data was 8 days so this is not possible) | . While we can adjust to scale to fit the real-world mean, the distribution does not match the real-world data - and for a parameter that influences the overall simulation, it is pretty far off. . Let&#39;s see what distribution looks more likely. . Finding a better fit: Gamma or Weibull distributions? . We have seen how different the actual COVID-19 $T_{Latent}$ and $T_{Infectious}$ were from the deterministic model using exponential distributions. . Here we want to find a better distribution, and one that immediatly comes to mind is the Gamma distribution. . Another is the Weibull distribution. . Characterizing the Gamma distribution . The gamma distribution is characterized by its shape parameter $k$ and its scale parameter $ theta$, where: $$Mean = k~ theta$$ . Characterizing the Weibull distribution . Similarly, the Weibull distribution is characterized by its shape parameter $k$ and its scale parameter $ theta$, where: $$Mean= lambda Gamma left(1+{ frac {1}{k}} right)$$ And: $$Median = lambda ( ln 2)^{1/k}$$ . Gamma distributed latent period . Let&#39;s first find a Gamma distribution to match $T_{Latent}$ data for COVID-19. . The mean is 5.2 days. . The range is [2,14] days and 95th percentile is 12.5 days, so we could translate this as follows: . 5th percentile = 2 days | 95th percentil = 12.5 days | . $$Mean = k~ theta$$ $$ leftrightarrow k~ theta = 5.2$$ $$ leftrightarrow k = frac{5.2}{ theta}$$ . We find the following parameters result in a pretty close distribution: . $loc = 1.8$ | $k = 0.9$ | $ theta = frac{5.2-loc}{k} = 3. dot{7}$ | . #collapse_hide p=100000 days=30 k=0.9 locg=1.8 theta=(5.2-locg)/k scalee=5.2 df = pd.DataFrame({ &#39;Exponential&#39;: expon.rvs(scale=scalee,size=p), &#39;Gamma&#39;: gamma.rvs(k,loc=locg,scale=theta,size=p) }) t=PrettyTable([&#39;Distribution&#39;, &#39;Mean&#39;, &#39;Median&#39;, &#39;5th percentile&#39;, &#39;95th percentile&#39;]) t.add_row([&#39;Exponential&#39;, df.Exponential.mean(), df.Exponential.median(), df.Exponential.quantile(q=0.05), df.Exponential.quantile(q=0.95)]) t.add_row([&#39;Gamma&#39;, df.Gamma.mean(), df.Gamma.median(), df.Gamma.quantile(q=0.05), df.Gamma.quantile(q=0.95)]) print(t) fig = go.Figure(data=[ go.Scatter(name=&#39;Gamma E --&gt; I&#39;, x=np.arange(days), y=gamma.cdf(np.arange(days), k, loc=locg, scale=theta), line={&#39;color&#39;:&#39;red&#39;}), go.Scatter(name=&#39;Expon E --&gt; I&#39;, x=np.arange(days), y=expon.cdf(np.arange(days), scale=scalee), line={&#39;color&#39;:&#39;blue&#39;}), ]) fig.update_layout( title={ &#39;text&#39;:&#39;Exponential vs. Gamma CDF&#39;, &#39;x&#39;:0.5, &#39;xanchor&#39;:&#39;center&#39; }, xaxis_title=&#39;Days&#39;, yaxis_title=&#39;Percent of exposed having become infectious&#39;, legend=dict( x=1, y=0, traceorder=&quot;reversed&quot;, ) ) fig.show() . . +--+-+-++--+ | Distribution | Mean | Median | 5th percentile | 95th percentile | +--+-+-++--+ | Exponential | 5.207469481987089 | 3.594278143717058 | 0.27075286628595824 | 15.622868963942889 | | Gamma | 5.196922877842177 | 4.054896063203861 | 1.9329997424767378 | 12.339859622859123 | +--+-+-++--+ . . . #collapse_hide p=10000 k=0.9 locg=1.8 theta=(5.2-locg)/k scalee=5.2 df = pd.DataFrame({ &#39;Exponential&#39;: expon.rvs(scale=scalee,size=p), &#39;Gamma&#39;: gamma.rvs(k,loc=locg,scale=theta,size=p) }) fig = px.histogram(df.stack().reset_index().rename(columns={&quot;level_1&quot;: &quot;Distribution&quot;}), x=0, color=&quot;Distribution&quot;, marginal=&#39;box&#39;) fig.update_layout( title={ &#39;text&#39;:&#39;Exponential vs. Gamma distributions&#39;, &#39;x&#39;:0.5, &#39;xanchor&#39;:&#39;center&#39; }, xaxis_title=&#39;Days&#39;, yaxis_title=&#39;Count&#39;, legend=dict( x=1, y=0, traceorder=&quot;normal&quot;, ) ) fig.show() . . . . Gamma or Weibull distributed infectious period . While we used a Gamma distribution for $T_{Latent}$ above, we do not have a mean for $T_{Infectious}$ data for COVID-19. We can still try to find a Gamma distribution that matches but it may be a bit more difficult to do. . With the median however, we could use the Weibull distribution as described earlier. . $$Median = lambda ( ln 2)^{1/k}$$ $$ leftrightarrow lambda = frac{Median}{( ln 2)^{1/k}}$$ $$ leftrightarrow lambda = frac{20}{( ln 2)^{1/k}}$$ . The range is [8,37] days so we could translate this as follows: . 5th percentile = 8 days | 95th percentil = 37 days | . We find the following parameters result in a pretty close Gamma distribution: . $loc = 3$ | $k = 4$ | $ theta = 4.25$ | . Similarly, we find the following parameters result in a pretty close Weibull distribution: . $loc = 2$ | $k = 2.3$ | $ lambda = frac{20-2}{( ln 2)^{1/k}} = 21.11$ | . #collapse_hide p = 10000 days=80 k=4 locg=3 theta=(20-locg)/k locw=2 wk = 2.3 wl = (20-locw)/(math.log(2)**(1/wk)) loce=0 scale=28.85-loce df = pd.DataFrame({ &#39;Exponential&#39;: expon.rvs(loc=loce, scale=scale,size=p), &#39;Gamma&#39;: gamma.rvs(k,loc=locg,scale=theta,size=p), &#39;Weibull&#39;: weibull_min.rvs(wk, loc=locw, scale=wl,size=p) }) t=PrettyTable([&#39;Distribution&#39;, &#39;Mean&#39;, &#39;Median&#39;, &#39;5th percentile&#39;, &#39;95th percentile&#39;]) t.add_row([&#39;Exponential&#39;, df.Exponential.mean(), df.Exponential.median(), df.Exponential.quantile(q=0.05), df.Exponential.quantile(q=0.95)]) t.add_row([&#39;Gamma&#39;, df.Gamma.mean(), df.Gamma.median(), df.Gamma.quantile(q=0.05), df.Gamma.quantile(q=0.95)]) t.add_row([&#39;Weibull&#39;, df.Weibull.mean(), df.Weibull.median(), df.Weibull.quantile(q=0.05), df.Weibull.quantile(q=0.95)]) print(t) fig = go.Figure(data=[ go.Scatter(name=&#39;Expon I --&gt; R&#39;, x=np.arange(days), y=expon.cdf(np.arange(days), loc=loce, scale=scale), line={&#39;color&#39;:&#39;blue&#39;}), go.Scatter(name=&#39;Gamma I --&gt; R&#39;, x=np.arange(days), y=gamma.cdf(np.arange(days), k, loc=locg, scale=theta), line={&#39;color&#39;:&#39;red&#39;}), go.Scatter(name=&#39;Weibull I --&gt; R&#39;, x=np.arange(days), y=weibull_min.cdf(np.arange(days), wk, loc=locw, scale=wl), line={&#39;color&#39;:&#39;green&#39;}) ]) fig.update_layout( title={ &#39;text&#39;:&#39;Exponential vs. Gamma vs. Weibull CDF&#39;, &#39;x&#39;:0.5, &#39;xanchor&#39;:&#39;center&#39; }, xaxis_title=&#39;Days&#39;, yaxis_title=&#39;Percent of exposed having become infectious&#39;, legend=dict( x=1, y=0, traceorder=&quot;normal&quot;, ) ) fig.show() . . +--+--+--+--+-+ | Distribution | Mean | Median | 5th percentile | 95th percentile | +--+--+--+--+-+ | Exponential | 28.476757690391107 | 19.996705193640878 | 1.5333146455434519 | 85.121378779367 | | Gamma | 20.075920288429813 | 18.6884046455234 | 8.612411926089568 | 36.12390356768179 | | Weibull | 20.624411927557794 | 19.93798874457553 | 7.7287057647939 | 35.71926543212359 | +--+--+--+--+-+ . . . #collapse_hide k=4 locg=3 theta=(20-locg)/k locw=2 wk = 2.3 wl = (20-locw)/(math.log(2)**(1/wk)) loce=0 scalee=28.85-loce p=10000 df = pd.DataFrame({ &#39;Exponential&#39;: expon.rvs(loc=loce, scale=scalee,size=p), &#39;Gamma&#39;: gamma.rvs(k,loc=locg,scale=theta,size=p), &#39;Weibull&#39;: weibull_min.rvs(wk, loc=locw, scale=wl,size=p) }) fig = px.histogram(df.stack().reset_index().rename(columns={&quot;level_1&quot;: &quot;Distribution&quot;}), x=0, color=&quot;Distribution&quot;, marginal=&#39;box&#39;) fig.update_layout( title={ &#39;text&#39;:&#39;Exponential vs. Gamma vs. Weibull distributions&#39;, &#39;x&#39;:0.5, &#39;xanchor&#39;:&#39;center&#39; }, xaxis_title=&#39;Days&#39;, yaxis_title=&#39;Count&#39;, legend=dict( x=1, y=0, traceorder=&quot;normal&quot;, ) ) fig.show() . . . . Discussion . $T_{Latent}$ is nicely matched with a Gamma distribution. . $T_{Infectious}$ is nicely matched by a Weibull distribution. . The take away however is that the exponential distribution matches neither - and in the case of $T_{Infectious}$ it is very far off. . We have seen in the previous posts that both of these periods have an impact on the peak proportion of infectious people and the duration of that peak. . Naturally, we need to investigate further the impact of changing the distributions from exponential to Gamma and Weibull on the simulations. . This is done in the next blog post where I build a new model to be able to take into account the actual distributions. .",
            "url": "https://jeffufpost.github.io/scattered-thoughts/probability%20distributions/modeling/seir/epidemiology/2020/03/25/proba-distrib.html",
            "relUrl": "/probability%20distributions/modeling/seir/epidemiology/2020/03/25/proba-distrib.html",
            "date": " ‚Ä¢ Mar 25, 2020"
        }
        
    
  
    
        ,"post5": {
            "title": "Epidemic modeling - Part 2",
            "content": ". Motivation for write-up . This is the 2nd part of a multi-part series blog post on modeling in epidemiology. . The COVID-19 pandemic has brought a lot of attention to the study of epidemiology and more specifically to the various mathematical models that are used to inform public health policies. Everyone has been trying to understand the growth or slowing of new cases and trying to predict the necessary sanitary resources. This blog post attempts to explain the foundations for some of the most used models and enlighten the reader on two key points. . After introducing the concepts of compartmentalization and disease dynamics in the first blog post, this second part is focused on developing a deterministic numerical solution for the SEIR model discussed there. . While normally the goal is to use real-world data to infer characteristics of the underlying disease (as will be done in later blog posts), here we want to use simulate the spread of a COVID-19 like disease in a population of 10000, and look at the effects of the different parameters on the spread. . Recall SEIR model equations . See the first blog post for derivation. . Continuous-time: . $ frac{ds(t)}{dt}=- beta i(t) s(t)$ | $ frac{de(t)}{dt}= beta i(t) s(t) - sigma e(t)$ | $ frac{di(t)}{dt}= sigma e(t) - gamma i(t)$ | $ frac{dr(t)}{dt}= gamma i(t)$ | . | Discrete-time: . $ Delta S = - beta I S Delta T$ | $ Delta E = ( beta I S - sigma E) Delta T$ | $ Delta I = ( sigma E - gamma I) Delta T$ | $ Delta R = gamma I Delta T$ | . | . Numerical solution to this deteministic population level model . Coding the SEIR model . To build the SEIR model we simply use the discrete-time set of equations above. . The model will thus take as input the following: . Initial proportion of S, E, I, and R in the population | $ beta$ parameter pertaining to the population in question | $ sigma$ and $ gamma$ parameters pertaining to the disease | Numbers of days to run the simulation | . #collapse_hide # Import required libraries import numpy as np import pandas as pd import plotly.express as px import plotly.graph_objects as go . . # Let&#39;s build a numerical solution def seir_model(init, parms, days): S_0, E_0, I_0, R_0 = init Epd, Ipd, Rpd = [0], [0], [0] S, E, I, R = [S_0], [E_0], [I_0], [R_0] dt=0.1 t = np.linspace(0,days,int(days/dt)) sigma, beta, gam = parms for _ in t[1:]: next_S = S[-1] - beta*S[-1]*I[-1]*dt Epd.append(beta*S[-1]*I[-1]*dt) next_E = E[-1] + (beta*S[-1]*I[-1] - sigma*E[-1])*dt Ipd.append(sigma*E[-1]*dt) next_I = I[-1] + (sigma*E[-1] - gam*I[-1])*dt Rpd.append(gam*I[-1]*dt) next_R = R[-1] + (gam*I[-1])*dt S.append(next_S) E.append(next_E) I.append(next_I) R.append(next_R) return np.stack([S, E, I, R, Epd, Ipd, Rpd]).T . COVID-19 parameters . Simulation parameters used for plot below: . Days = 100 | Population = 10000 | Number of susceptible people on day 0 = 9999 | Number of exposed people on day 0 = 1 | No infected or recovered people on day 0 | . A lot of research is ongoing into the COVID-19 characteristics of $ beta$, $ sigma$, and $ gamma$. . However, these are complex studies that require a lot of data and so far we have little information to go on. . The literature suggests the following: . $ underline{T_{Incubation}}$: | . The mean is 5-6 days but it can range anywhere from 2-14 days 1 2 . Another paper reports a mean incubation period of 5.2 days and the 95th percentile at 12.5 days 3. . There are reports of pre-symptomatic infections[^2], but these are reportedly rare [^1] so in the following models we will assume: $$T_{Incubation} = T_{Latent}$$ And so: $$ sigma = frac{1}{5.2} days^{-1}$$ . $ underline{T_{Infectious}}$: | . Again it is very difficult to say for sure and the period of communicability is very uncertain for COVID-19. . Research suggests a median of 20 days of viral shedding after onset of symptoms 4. . Ranging from 8 to 37 days in survivors. . While it is noted PCR positivity does not necessarily reflect the infectious period (virus may not be viable but the PCR amplification will result in a positive), for the purpose of this blog post we will assume the following: $$T_{Infectious} = T_{Clinical}$$ To obtain an exponential distribution with median M, the scale A is calculated as follows: $$A = frac{M}{ ln2} = frac{20}{ ln2}$$ This results in $$ gamma = frac{ ln2}{20} = frac{1}{28.85} days^{-1}$$ . $ underline{Beta= beta}$: | . While difficult to estimate this parameter as there is a lot of variation between countries, cultures, societal norms, etc.. a little thought experiment can help us evaluate the value for $ beta = r rho$ in Switerland or France for example. . If no control measures are put in place and people do not change habits (as is the case in this blog post), we can expect the following: . Average number of contacts per day: | $$r = 10 contacts per day$$ . Average probability of transmission from contact: | $$ rho = 5 %$$ . And so: $$ beta = r rho = 0.5$$ . . WHO COVID-19 Situation Report 73&#8617; . | CDC COVID-19 FAQ&#8617; . | Early Transmission Dynamics in Wuhan, China, of Novel Coronavirus‚ÄìInfected Pneumonia&#8617; . | Clinical course and mortality risk of server COVID-1930633-4/fulltext)&#8617; . | Running the simulation . #collapse_hide #Define parameters days = 200 N = 10000 init = 1 - 1/N, 1/N, 0, 0 sigma = 1/5.2 beta = 0.5 gam = 1/28.85 parms = sigma, beta, gam # Run simulation results_avg = seir_model(init, parms, days) . . #collapse_hide fig = go.Figure(data=[ go.Scatter(name=&#39;S&#39;, x=np.linspace(0,days,days*10), y=results_avg.T[0], line={&#39;dash&#39;:&#39;solid&#39;, &#39;color&#39;:&#39;blue&#39;}), go.Scatter(name=&#39;E&#39;, x=np.linspace(0,days,days*10), y=results_avg.T[1], line={&#39;dash&#39;:&#39;solid&#39;, &#39;color&#39;:&#39;yellow&#39;}), go.Scatter(name=&#39;I&#39;, x=np.linspace(0,days,days*10), y=results_avg.T[2], line={&#39;dash&#39;:&#39;solid&#39;, &#39;color&#39;:&#39;red&#39;}), go.Scatter(name=&#39;R&#39;, x=np.linspace(0,days,days*10), y=results_avg.T[3], line={&#39;dash&#39;:&#39;solid&#39;, &#39;color&#39;:&#39;green&#39;}), ]) fig.update_layout( xaxis_title = &#39;Day&#39;, yaxis_title = &#39;Proportion of population&#39;, title={ &#39;text&#39;:&#39;Deterministic SEIR model - COVID-19 parameters&#39;, &#39;x&#39;:0.5, &#39;xanchor&#39;:&#39;center&#39; } ) fig.show() . . . . Qualitative analysis of $ beta$, $ sigma$, and $ gamma$ . Effect of $ sigma$ ($T_{Latent}$) . Let&#39;s have a look at the effect of $ sigma$ (or inversely, the latent period) on the SEIR simulation. . A higher $ sigma$ means shorter average latent period, and vice-versa. . #collapse_hide ## Let&#39;s try to see how the model changes days = 1000 N = 10000 init = 1 - 1/N, 1/N, 0, 0 sigma_high = 1 # 1 --&gt; Average 1 day from E --&gt; I (ressembles SIR model) sigma_low = 1/100 #10 days on average, twice as long as COVID-19 sigma_covid = 1/5.2 beta = 0.5 gam = 1/28.85 parms_fastEI = sigma_high, beta, gam parms_slowEI = sigma_low, beta, gam parms_avg = sigma_covid, beta, gam # Run simulation results_fastEtoI = seir_model(init, parms_fastEI, days) results_slowEtoI = seir_model(init, parms_slowEI, days) results_avg = seir_model(init, parms_avg, days) . . #collapse_hide fig = go.Figure(data=[ go.Scatter(name=r&#39;$S: sigma_{COVID}$&#39;, x=np.linspace(0,days,days*10), y=results_avg.T[0], line={&#39;dash&#39;:&#39;solid&#39;, &#39;color&#39;:&#39;blue&#39;}, legendgroup=&quot;COVID&quot;, hoverinfo=&#39;x+y&#39;), go.Scatter(name=r&#39;$S: sigma_{COVID}$&#39;, x=np.linspace(0,days,days*10), y=results_avg.T[1], line={&#39;dash&#39;:&#39;solid&#39;, &#39;color&#39;:&#39;yellow&#39;}, legendgroup=&quot;COVID&quot;, hoverinfo=&#39;x+y&#39;), go.Scatter(name=r&#39;$S: sigma_{COVID}$&#39;, x=np.linspace(0,days,days*10), y=results_avg.T[2], line={&#39;dash&#39;:&#39;solid&#39;, &#39;color&#39;:&#39;red&#39;}, legendgroup=&quot;COVID&quot;, hoverinfo=&#39;x+y&#39;), go.Scatter(name=r&#39;$S: sigma_{COVID}$&#39;, x=np.linspace(0,days,days*10), y=results_avg.T[3], line={&#39;dash&#39;:&#39;solid&#39;, &#39;color&#39;:&#39;green&#39;}, legendgroup=&quot;COVID&quot;, hoverinfo=&#39;x+y&#39;), go.Scatter(name=r&#39;$S: sigma_{high}$&#39;, x=np.linspace(0,days,days*10), y=results_fastEtoI.T[0], line={&#39;dash&#39;:&#39;dash&#39;,&#39;color&#39;:&#39;blue&#39;}, legendgroup=&quot;high&quot;, hoverinfo=&#39;x+y&#39;), go.Scatter(name=r&#39;$S: sigma_{high}$&#39;, x=np.linspace(0,days,days*10), y=results_fastEtoI.T[1], line={&#39;dash&#39;:&#39;dash&#39;, &#39;color&#39;:&#39;yellow&#39;}, legendgroup=&quot;high&quot;, hoverinfo=&#39;x+y&#39;), go.Scatter(name=r&#39;$S: sigma_{high}$&#39;, x=np.linspace(0,days,days*10), y=results_fastEtoI.T[2], line={&#39;dash&#39;:&#39;dash&#39;, &#39;color&#39;:&#39;red&#39;}, legendgroup=&quot;high&quot;, hoverinfo=&#39;x+y&#39;), go.Scatter(name=r&#39;$S: sigma_{high}$&#39;, x=np.linspace(0,days,days*10), y=results_fastEtoI.T[3], line={&#39;dash&#39;:&#39;dash&#39;, &#39;color&#39;:&#39;green&#39;}, legendgroup=&quot;high&quot;, hoverinfo=&#39;x+y&#39;), go.Scatter(name=r&#39;$S: sigma_{low}$&#39;, x=np.linspace(0,days,days*10), y=results_slowEtoI.T[0], line={&#39;dash&#39;:&#39;dot&#39;, &#39;color&#39;:&#39;blue&#39;}, legendgroup=&quot;slow&quot;, hoverinfo=&#39;x+y&#39;), go.Scatter(name=r&#39;$S: sigma_{low}$&#39;, x=np.linspace(0,days,days*10), y=results_slowEtoI.T[1], line={&#39;dash&#39;:&#39;dot&#39;, &#39;color&#39;:&#39;yellow&#39;}, legendgroup=&quot;slow&quot;, hoverinfo=&#39;x+y&#39;), go.Scatter(name=r&#39;$S: sigma_{low}$&#39;, x=np.linspace(0,days,days*10), y=results_slowEtoI.T[2], line={&#39;dash&#39;:&#39;dot&#39;, &#39;color&#39;:&#39;red&#39;}, legendgroup=&quot;slow&quot;, hoverinfo=&#39;x+y&#39;), go.Scatter(name=r&#39;$S: sigma_{low}$&#39;, x=np.linspace(0,days,days*10), y=results_slowEtoI.T[3], line={&#39;dash&#39;:&#39;dot&#39;, &#39;color&#39;:&#39;green&#39;}, legendgroup=&quot;slow&quot;, hoverinfo=&#39;x+y&#39;), ]) fig.update_layout( xaxis_title = &#39;Day&#39;, yaxis_title = &#39;Proportion of population&#39;, title={ &#39;text&#39;:r&#39;$ text{Effect of } sigma text{on Deterministic SEIR model}$&#39;, &#39;x&#39;:0.5, &#39;xanchor&#39;:&#39;center&#39; } ) fig.show() . . . . We notice a few things from the plot above on the impact of the average time from E &rarr; I: . The shorter the latent period: the faster the epidemic propogates in the population | the higher the peak of infected individuals will be (meaning a higher chance hospital resources will be saturated) | . | However, the latent period has no impact on the total number of individuals infected over the entire time of the epidemic. | . Effect of $ beta = r~ rho$ . Let&#39;s have a look at the effect of $ beta$ on the SEIR simulation. . A higher $ beta$ can either mean a higher average number of contacts per day ($r$) in the population and/or a higher probability of transmission of disease from I &rarr; S. . The opposite holds also. . #collapse_hide ## Let&#39;s try to see how the model changes days = 500 N = 10000 init = 1 - 1/N, 1/N, 0, 0 sigma_avg = 1/5.2 beta_avg = 0.5 beta_noepi = 1/30 beta_low = 0.1 beta_high = 4 gam = 1/28.85 parms_avg = sigma_avg, beta_avg, gam parms_noepi = sigma_avg, beta_noepi, gam parms_low = sigma_avg, beta_low, gam parms_high = sigma_avg, beta_high, gam # Run simulation results_avg = seir_model(init, parms_avg, days) results_noepi = seir_model(init, parms_noepi, days) results_low = seir_model(init, parms_low, days) results_high = seir_model(init, parms_high, days) . . #collapse_hide fig = go.Figure(data=[ go.Scatter(name=r&#39;$S: beta_{COVID}$&#39;, x=np.linspace(0,days,days*10), y=results_avg.T[0], line={&#39;dash&#39;:&#39;solid&#39;, &#39;color&#39;:&#39;blue&#39;}, legendgroup=&quot;COVID&quot;), go.Scatter(name=r&#39;$E: beta_{COVID}$&#39;, x=np.linspace(0,days,days*10), y=results_avg.T[1], line={&#39;dash&#39;:&#39;solid&#39;, &#39;color&#39;:&#39;yellow&#39;}, legendgroup=&quot;COVID&quot;), go.Scatter(name=r&#39;$I: beta_{COVID}$&#39;, x=np.linspace(0,days,days*10), y=results_avg.T[2], line={&#39;dash&#39;:&#39;solid&#39;, &#39;color&#39;:&#39;red&#39;}, legendgroup=&quot;COVID&quot;), go.Scatter(name=r&#39;$R: beta_{COVID}$&#39;, x=np.linspace(0,days,days*10), y=results_avg.T[3], line={&#39;dash&#39;:&#39;solid&#39;, &#39;color&#39;:&#39;green&#39;}, legendgroup=&quot;COVID&quot;), go.Scatter(name=r&#39;$S: beta_{noepi}$&#39;, x=np.linspace(0,days,days*10), y=results_noepi.T[0], line={&#39;dash&#39;:&#39;dashdot&#39;,&#39;color&#39;:&#39;blue&#39;}, legendgroup=&quot;noepi&quot;), go.Scatter(name=r&#39;$E: beta_{noepi}$&#39;, x=np.linspace(0,days,days*10), y=results_noepi.T[1], line={&#39;dash&#39;:&#39;dashdot&#39;, &#39;color&#39;:&#39;yellow&#39;}, legendgroup=&quot;noepi&quot;), go.Scatter(name=r&#39;$I: beta_{noepi}$&#39;, x=np.linspace(0,days,days*10), y=results_noepi.T[2], line={&#39;dash&#39;:&#39;dashdot&#39;, &#39;color&#39;:&#39;red&#39;}, legendgroup=&quot;noepi&quot;), go.Scatter(name=r&#39;$R: beta_{noepi}$&#39;, x=np.linspace(0,days,days*10), y=results_noepi.T[3], line={&#39;dash&#39;:&#39;dashdot&#39;, &#39;color&#39;:&#39;green&#39;}, legendgroup=&quot;noepi&quot;), go.Scatter(name=r&#39;$S: beta_{low}$&#39;, x=np.linspace(0,days,days*10), y=results_low.T[0], line={&#39;dash&#39;:&#39;dash&#39;,&#39;color&#39;:&#39;blue&#39;}, legendgroup=&quot;low&quot;), go.Scatter(name=r&#39;$E: beta_{low}$&#39;, x=np.linspace(0,days,days*10), y=results_low.T[1], line={&#39;dash&#39;:&#39;dash&#39;, &#39;color&#39;:&#39;yellow&#39;}, legendgroup=&quot;low&quot;), go.Scatter(name=r&#39;$I: beta_{low}$&#39;, x=np.linspace(0,days,days*10), y=results_low.T[2], line={&#39;dash&#39;:&#39;dash&#39;, &#39;color&#39;:&#39;red&#39;}, legendgroup=&quot;low&quot;), go.Scatter(name=r&#39;$R: beta_{low}$&#39;, x=np.linspace(0,days,days*10), y=results_low.T[3], line={&#39;dash&#39;:&#39;dash&#39;, &#39;color&#39;:&#39;green&#39;}, legendgroup=&quot;low&quot;), go.Scatter(name=r&#39;$S: beta_{high}$&#39;, x=np.linspace(0,days,days*10), y=results_high.T[0], line={&#39;dash&#39;:&#39;dot&#39;, &#39;color&#39;:&#39;blue&#39;}, legendgroup=&quot;high&quot;), go.Scatter(name=r&#39;$E: beta_{high}$&#39;, x=np.linspace(0,days,days*10), y=results_high.T[1], line={&#39;dash&#39;:&#39;dot&#39;, &#39;color&#39;:&#39;yellow&#39;}, legendgroup=&quot;high&quot;), go.Scatter(name=r&#39;$I: beta_{high}$&#39;, x=np.linspace(0,days,days*10), y=results_high.T[2], line={&#39;dash&#39;:&#39;dot&#39;, &#39;color&#39;:&#39;red&#39;}, legendgroup=&quot;high&quot;), go.Scatter(name=r&#39;$R: beta_{high}$&#39;, x=np.linspace(0,days,days*10), y=results_high.T[3], line={&#39;dash&#39;:&#39;dot&#39;, &#39;color&#39;:&#39;green&#39;}, legendgroup=&quot;high&quot;), ]) fig.update_layout( xaxis_title = &#39;Day&#39;, yaxis_title = &#39;Proportion of population&#39;, title={ &#39;text&#39;:r&#39;$ text{Effect of } beta text{on Deterministic SEIR model}$&#39;, &#39;x&#39;:0.5, &#39;xanchor&#39;:&#39;center&#39; } ) fig.show() . . . . We notice a few things from the plot above on the impact of $ beta$: . The higher $ beta$ is: the faster the epidemic seems to propogate in the population | the higher the peak of infected individuals seems to be (meaning a higher chance hospital resources will be saturated) | . | $ beta$ also appears to affect the overall number of people infected over the course of the epidemic A low $ beta$ means a low $R_0$ and we have seen in the first part of this blog that no epidemic occurs when $R_0 &lt; 1$ | But even if $R_0 &gt; 1$, keeping $ beta$ low reduces the total number of people infected | . | . Effect of $ gamma$ ($T_{Infectious}$) . Let&#39;s have a look at the effect of $ gamma$ on the SEIR simulation. . A higher $ gamma$ means a shorter infectious period, and vice-versa. . #collapse_hide ## Let&#39;s try to see how the model changes days = 500 N = 10000 init = 1 - 1/N, 1/N, 0, 0 sigma_avg = 1/5.2 beta = 0.5 gam_avg = 1/28.85 gam_low = 1/200 gam_high = 0.2 parms_fastIR = sigma_avg, beta, gam_high parms_slowIR = sigma_avg, beta, gam_low parms_avg = sigma_avg, beta, gam_avg # Run simulation results_fastItoR = seir_model(init, parms_fastIR, days) results_slowItoR = seir_model(init, parms_slowIR, days) results_avg = seir_model(init, parms_avg, days) . . #collapse_hide fig = go.Figure(data=[ go.Scatter(name=r&#39;$S: gamma_{COVID}$&#39;, x=np.linspace(0,days,days*10), y=results_avg.T[0], line={&#39;dash&#39;:&#39;solid&#39;, &#39;color&#39;:&#39;blue&#39;}, legendgroup=&quot;COVID&quot;, hoverinfo=&#39;x+y&#39;), go.Scatter(name=r&#39;$S: gamma_{COVID}$&#39;, x=np.linspace(0,days,days*10), y=results_avg.T[1], line={&#39;dash&#39;:&#39;solid&#39;, &#39;color&#39;:&#39;yellow&#39;}, legendgroup=&quot;COVID&quot;, hoverinfo=&#39;x+y&#39;), go.Scatter(name=r&#39;$S: gamma_{COVID}$&#39;, x=np.linspace(0,days,days*10), y=results_avg.T[2], line={&#39;dash&#39;:&#39;solid&#39;, &#39;color&#39;:&#39;red&#39;}, legendgroup=&quot;COVID&quot;, hoverinfo=&#39;x+y&#39;), go.Scatter(name=r&#39;$S: gamma_{COVID}$&#39;, x=np.linspace(0,days,days*10), y=results_avg.T[3], line={&#39;dash&#39;:&#39;solid&#39;, &#39;color&#39;:&#39;green&#39;}, legendgroup=&quot;COVID&quot;, hoverinfo=&#39;x+y&#39;), go.Scatter(name=r&#39;$S: gamma_{high}$&#39;, x=np.linspace(0,days,days*10), y=results_fastItoR.T[0], line={&#39;dash&#39;:&#39;dash&#39;,&#39;color&#39;:&#39;blue&#39;}, legendgroup=&quot;fast&quot;, hoverinfo=&#39;x+y&#39;), go.Scatter(name=r&#39;$S: gamma_{high}$&#39;, x=np.linspace(0,days,days*10), y=results_fastItoR.T[1], line={&#39;dash&#39;:&#39;dash&#39;, &#39;color&#39;:&#39;yellow&#39;}, legendgroup=&quot;fast&quot;, hoverinfo=&#39;x+y&#39;), go.Scatter(name=r&#39;$S: gamma_{high}$&#39;, x=np.linspace(0,days,days*10), y=results_fastItoR.T[2], line={&#39;dash&#39;:&#39;dash&#39;, &#39;color&#39;:&#39;red&#39;}, legendgroup=&quot;fast&quot;, hoverinfo=&#39;x+y&#39;), go.Scatter(name=r&#39;$S: gamma_{high}$&#39;, x=np.linspace(0,days,days*10), y=results_fastItoR.T[3], line={&#39;dash&#39;:&#39;dash&#39;, &#39;color&#39;:&#39;green&#39;}, legendgroup=&quot;fast&quot;, hoverinfo=&#39;x+y&#39;), go.Scatter(name=r&#39;$S: gamma_{low}$&#39;, x=np.linspace(0,days,days*10), y=results_slowItoR.T[0], line={&#39;dash&#39;:&#39;dot&#39;, &#39;color&#39;:&#39;blue&#39;}, legendgroup=&quot;slow&quot;, hoverinfo=&#39;x+y&#39;), go.Scatter(name=r&#39;$S: gamma_{low}$&#39;, x=np.linspace(0,days,days*10), y=results_slowItoR.T[1], line={&#39;dash&#39;:&#39;dot&#39;, &#39;color&#39;:&#39;yellow&#39;}, legendgroup=&quot;slow&quot;, hoverinfo=&#39;x+y&#39;), go.Scatter(name=r&#39;$S: gamma_{low}$&#39;, x=np.linspace(0,days,days*10), y=results_slowItoR.T[2], line={&#39;dash&#39;:&#39;dot&#39;, &#39;color&#39;:&#39;red&#39;}, legendgroup=&quot;slow&quot;, hoverinfo=&#39;x+y&#39;), go.Scatter(name=r&#39;$S: gamma_{low}$&#39;, x=np.linspace(0,days,days*10), y=results_slowItoR.T[3], line={&#39;dash&#39;:&#39;dot&#39;, &#39;color&#39;:&#39;green&#39;}, legendgroup=&quot;slow&quot;, hoverinfo=&#39;x+y&#39;), ]) fig.update_layout( xaxis_title = &#39;Day&#39;, yaxis_title = &#39;Proportion of population&#39;, title={ &#39;text&#39;:r&#39;$ text{Effect of } gamma text{on Deterministic SEIR model}$&#39;, &#39;x&#39;:0.5, &#39;xanchor&#39;:&#39;center&#39; } ) fig.show() . . . . We notice a few things from the plot above on the impact of the infectious period: . The longer the infectious period: the faster the epidemic propogates in the population | the higher the peak of infectious individuals will be and the longer it will last (meaning a higher chance hospital resources will be saturated) | . | As opposed to the latent period above, but similarly as $ beta$, the infectious period has an impact on the total number of individuals infected over the entire time of the epidemic With no epidemic if $ gamma &gt; beta$ | . | . Discussion . So we can see the latent and infectious periods, along with the value of $ beta$ are critical components in how the model will react. . Worth noting also is that the higher $R_0$ is, the faster the epidemic spreads and the higher the peak of infectious individuals will be (see further blog posts for some nuance on this). . Notably, and as predicted in part 1 of the blog series, no epidemic occurs if: $$R_0 &lt; 1$$ In other words, no epidemic if: $$ beta &lt; gamma$$ . There are major flaws with this model however. While this model is deterministic and uses average time to model $ sigma$ and $ gamma$, this is a major flaw and does not represent the reality for most diseases. . Part 3 of this blog series will discuss this further. .",
            "url": "https://jeffufpost.github.io/scattered-thoughts/modeling/seir/epidemiology/2020/03/18/deterministic-numerical-solutions.html",
            "relUrl": "/modeling/seir/epidemiology/2020/03/18/deterministic-numerical-solutions.html",
            "date": " ‚Ä¢ Mar 18, 2020"
        }
        
    
  
    
        ,"post6": {
            "title": "Epidemic modeling - Part 1",
            "content": ". Motivation for write-up . This is the 1st part of a multi-part series blog post on modeling in epidemiology. . The COVID-19 pandemic has brought a lot of attention to the study of epidemiology and more specifically to the various mathematical models that are used to inform public health policies. Everyone has been trying to understand the growth or slowing of new cases and trying to predict the necessary sanitary resources. This blog post attempts to explain the foundations for some of the most used models and enlighten the reader on a few important points. . In this first post I want to introduce the concept of compartmentalization and how it forms the basis for studying disease dynamics on the population level. . How to model infectious diseases on population level ? . Compartments . When modelling infectious diseases, and pandemics in particular, a key ask is to predict the number of infected people at any given time in order to estimate the sanitary resources that will be necessary. . From this simple qestion results the idea of compartmentalization of the population i.e. the division of the population into the two most basic categories: . those that are infected | those that are not | . This is ultimately the foundation for all compartmental models in epidemiology. . The nuances between the models then come from how the above two groups are further compartmentalized. That is to say, how we decide the composition of the infected and the not-infected groups. . For example, the non-infected group could be further sub-categorized into: . Susceptible | Immune | . And the infected group into: . Asymptomatic | Symptomatic | . Or, another option, into: . No treatment necessary | Require treatment: Local Doctor visit | Hospitalization | Admitted to intensive care unit | . | . As you can see there are many ways to do this, but the more categories you have, the more difficult it might become to model. Usually we determine these subcategories in order to match available data. . Dynamics . While the compartments describe the state any individual can be in at a certain point in time, the dynamics describe the ways in which the compartments interact with each other. . I want to underline the separation between disease dynamics on the individual level, and that on the population level below. . Individual level disease dynamics: | . This describes, on the individual level, the progression of the disease i.e. how one person can go from one state to another (one compartment to another) . For example: how does a healthy person become ill and what is the clinical course of the disease for this person? . Population-level dynamics: | . On the other hand, the population level dynamics describe, on a population level, how the total number of individuals in each compartment vary over time. . We will see more on this in the next blog posts. . Two simple examples - the SIR and SEIR models . Let&#39;s have a look at a basic compartmental model, first the SIR model. . S --&gt; Susceptible state: | . An S individual is simply someone susceptible to the disease, that is anyone in the population who is healthy and not immune to the disease. . I --&gt; Infectious state: | . Once an individual is exposed to the disease he will develop this disease and become infectious. . R --&gt; Recovered state: | . An individual will either fight off the infection (with the help or not of treatment) or die. These are all included in the R state. . In the basic SIR model, anyone R has aquired full and infinite immunity and cannot catch the disease again (of course many variations can be included to reflect more closely a disease). . In this write-up and in the following blog posts we will focus on the SEIR models, which are similar to the SIR compartments above with the additional E state between S and I. . E --&gt; Exposed state: | . The exposed state is the state when an individual has been exposed to the disease, but has not become infectious yet. . Some important vocabulary . $ underline{Infectious period:}$ | . Also called the period of communicability, the infectious period is the time during which an individual can transmit the disease to another: $T_{Infectious}$ . $ underline{Clinical infection period:}$ | . This period corresponds to the period where the infected indvidual shows symptoms: $T_{Clinical}$ . $ underline{Latent period:}$ | . The latent period is the time between exposure of an individual and the start of the period of communicability of that individual: $T_{Latent}$ . $ underline{Incubation period:}$ | . The incubation period on the other hand, is the time from exposure of an individual to development of the infection (appearance of disease): $T_{Incubation}$ . It should be noted the latent period and incubation period are not necessarily the same. . $ underline{T_{Latent} &lt; T_{Incubation}}$: | . In this case, an individual who has been exposed becomes infectious before the development of disease. . We call this a subclinical infection and during that time the individual is called an asymptomatic carrier. . $ underline{T_{Latent} &gt; T_{Incubation}:}$ | . In other cases, the latent period can be longer than the incubation period, eg: smallpox. . $ underline{T_{Latent} + T_{Infectious} &gt; T_{Incubation} + T_{Clinical}:}$ | . Another case of subclinical infection resulting in asymptomatic carriers occurs when the end of clinical infection (of disease) happens earlier than the end of the period of communicability (see Wikipedia figure below) . Overall, these asymptomatic carriers can be a significant difficutly to overcome epidemics. . . $ underline{Basic reproduction number:}$ | . The basic reproduction number $R_0$ is the measure of secondary infections in a susceptible population. . In other words, it is the number of people that each infectious individual will infect over the time of their infectious period. . Example: . If an infectious individual infects 3 other individuals over the course of his infection, his $R_0$ is 3. . This number is a very important element in the spreading dynamics (see derivation below). . A closer look at the SEIR model . Individual-level disease dynamic . As explained above, the individual-level disease dynamic describes the progression of disease within an individual i.e. the progression of an individual from one state to another. . In the models used here (SEIR model), an individual starts at S (although an initial exposed or infectious person is injected into the population at time t=0). . | If exposed to the disease he will move into the state E. . | After which he will move to the I state with probability 1, but in a time unique to himself. . | Again after which he will move into the state R with probability 1, and again in a time unique to him. . | From state R he will stay in state R (either dead or has aquired full and inifite immunity). . | . Let&#39;s have a closer look: . S &rarr; E . The chances of an individual going from S &rarr; E depends on three things: . the number of contacts the person has per unit time (given by $r$) | the chance a given contact is with an I - infectious individual (the higher the number of I in the population, the higher the chance) | the chance of an S contracting the disease from a contact with an I (given by $ rho$) | E &rarr; I . The latent period . All people exposed will eventually develop disease. . However, individually, a person might go from E to I on the first day, or after 10 days, this is unique to the individual. . Every additional day following exposure the probability of this individual to go from E &rarr; I increases (we will have a look at the probability distribution and its importance later). . I &rarr; R . The period of communicability . Similarly, all infectious people will recover (or die). . Again, individually, a person might go from I to R in 5 days or in 15 days, this time is the recovery time and is proper to the individual. . Population level dynamics . Most basic models tend to disregard the notion of individual dynamics above in favor of poopulation level dynamics. . That is to say the models tend to model disease on a population level without looking at the specific pogression of disease within the individuals and using averages instead (although the S &rarr; E uses the same logic as above). . Below is an explanation for such an SEIR model with its mathematical formulation. . Note no births or deaths are included. . S &rarr; E . As stated above, going from S to E on a particular day depends on these three characteristics: . the proportion of infectious people in the population on that day: $i(t) = frac{I(t)}{N}$ | the number of contacts an individual has per day: $r$ | the chance for an S to contract the disease after contact with an I: $ rho$ | . We can combine the last two into $ beta = r rho$ . On a population-level however, the number of S that will become E also depends on the proportion of S in the population (of course if there are no S, no one will become E of course). . So we add the following requirement: . the proportion of susceptible people in the population on that day: $s(t) = frac{S(t)}{N}$ | . So the change in the number of S in a population on a given day is equal to: . $- beta i(t) s(t)$ . (note the negative sign to indicate the number of S is diminishing as they become exposed) . Hence we can formulate this mathematically as follows: . Discrete-time: $$ Delta S = - beta I S Delta T$$ | Continuous-time: $$ frac{ds(t)}{dt}=- beta i(t) s(t)$$ | . E &rarr; I . We have seen above how each individual goes from E to I. . On a population level, the number of E changes in two ways: . new additions following S &rarr; E | reduction following E &rarr; I | . We already know the number from S &rarr; E is: . $$ beta i(t) s(t)$$ . So how can we model the number of E &rarr; I? . While individually this is a bit more complicated to model and pertains to the specific probability distribution of the latent period, on a population level we can use the average time it takes - this is what most models do (part 3 of this blog post will show why this is wrong for COVID-19). . Let&#39;s say average latent period is . $$ frac{1}{ sigma}$$ . then we know that every unit time that goes by, we have . $$ sigma E$$ . individuals that transition from E &rarr; I. . Mathematically, we write this as : . Discrete-time: $$ Delta E = ( beta I S- sigma E) Delta T$$ | Continuous-time: $$ frac{de(t)}{dt}= beta i(t) s(t) - sigma e(t)$$ | . I &rarr; R . Similarly as above, we have seen above how each individual goes from I to R but this does not tell us about the population level dynamics. . On a population level, the number of I changes in two ways: . new additions following E &rarr; I | reduction following I &rarr; R | . We know the number from E &rarr; I is: . $$ sigma e(t)$$ . How can we model the number of I &rarr; R? . Again, while individually this is complicated, on a population level, how about averaging out the period of infectiousness, this is what most models do. . Let&#39;s say average time of infectiousness is . $$ frac{1}{ gamma}$$ . Then we have: . Discrete-time: $$ Delta I = ( sigma E - gamma I) Delta T$$ | Continuous-time: $$ frac{di(t)}{dt}= sigma e(t) - gamma i(t)$$ | . R &rarr; R . Finally, it is simple to model the number of individuals in R state with the following equation: . Discrete-time: $$ Delta R = gamma I Delta T$$ | Continuous-time: $$ frac{dr(t)}{dt}= gamma i(t)$$ | . Effective and Basic Reproduction Numbers: $R$ and $R_0$ respectively . As stated above, $R_0$ is the measure of secondary infections. Let&#39;s have a look how we can characterize it. . Understanding how the infection spreads . Any individual in state I (infectious) will contaminate others according to the following: . Number of contacts the individual has per day given by: $r_i$ | Probability to infect an S after contact given by: $ rho_i$ | Probability of a contact being with an S given by: $ frac{S(t)}{N} = s(t)$ | The period of infectiousness of the individual given by [$j_i, j_i+ frac{1}{ tau_i}$] (where $j_i$ is the first day of infectiousness for that individual and $ frac{1}{ tau_i}$ is that individuals&#39; time of infectiousness) | . Remember $r_i rho_i= beta_i$ . Derivation of $R$ for each individual . Let&#39;s call the measure of $R$ for any individual $R_i$. . From the parameters above we can write $R_i$ for each infectious individual as the sum of secondary infections per day of infectiousness as below: . Discrete-time: $$R_i = sum_{Day=j_i}^{j_i+ frac{1}{ tau_i}} beta_i frac{S(Day)}{N}$$ *Continuous-time: $$R_i = int_{j_i}^{j_i+ frac{1}{ tau_i}} beta_i s(t) dt$$ | . Finding $R_0$ of each individual by making assumptions . $R_{0,i}$ is the measure of $R_i$ in a susceptible population, i.e. when: $$S = N$$ . In other words: $$R_{0,i} = R_i ~ frac{N}{S}$$ . If we make the following assumptions: . s(t) is constant over the course of infectiousness of an individual: $$s(t) = s(t+ frac{1}{ tau_i})$$ | $ beta_i$ is a constant and does not vary over the course of time (no control measures) | . Then the equation for $R_{0,i}$ reduces to the following: $$R_{0,i} = [ beta_i]_{j_i}^{j_i+ frac{1}{ tau_i}} = frac{ beta_i}{ tau_i}$$ . We can see the basic reproduction number of an individual is fully characterized by the $ beta_i$ and the $ tau_i$ of that individual. . $R_0$ for a population . To a generalize to a population-level, we can simply find the expected value for the equation above: $$R_0 = E[R_{0,i}] = frac{E[ beta_i]}{E[ tau_i]}$$ . Assuming: . $E[ beta_i] = beta$ | $E[ tau_i] = gamma$ | . We can write: $$R_0 = frac{ beta}{ gamma}$$ . Herd Immunity . As just described, $R$ is the measure of secondary infections, and $R_0$ is the measure of secondary infections in a susceptible population where $R=R_0~s(t)$. . It is easy to understand that if each infectious individual contaminates less than 1 other individual on average ($R &lt; 1$) then the number of exposed, and eventually infectious, individuals will diminish and tend to 0. . On the other hand, if each infectious individual contaminates more than 1 other individual ($R &gt; 1$) then the number of infectious individuals will rise (chance of epidemic). . Mathematical formulation: . $$ frac{d~e(t)}{dt} = beta~i(t)~s(t) - gamma~i(t)$$ $$ leftrightarrow frac{d~e(t)}{dt} = R_0~ gamma~i(t)~s(t) - gamma~i(t)$$ $$ leftrightarrow frac{d~e(t)}{dt} = gamma~i(t)~(R_0~s(t) - 1)= gamma~i(t)~(R - 1)$$ . And so we find that in a population where $ gammaƒ©(t)&gt;0$: $$ frac{d~e(t)}{dt} = 0$$ $$ leftrightarrow R-1 = 0$$ $$ leftrightarrow R = 1$$ . If $R&lt;1$ then $ frac{d~e(t)}{dt} &lt; 0$ . Herd immunity threshold: . The herd immunity threshold is the point at which enough of the population is immune to the disease (not susceptible) in order to have $R &lt; 1$ and can be calculated as follows: $$R = R_0 ~ s(t)$$ . We know the proportion of the population immune to the disease is: $$Immune(t) = 1-s(t)$$ $$ leftrightarrow s(t)=1-Immune(t)$$ . The threshold of $R = 1$ is achieved when: $$R_0 ~s(t) = 1$$ $$ leftrightarrow R_0 ~(1-Immune(t)) = 1$$ $$ leftrightarrow 1-Immune(t) = frac{1}{R_0}$$ $$ leftrightarrow Immune(t) = 1- frac{1}{R_0}$$ . When the proportion of immune individuals in a population reaches $1- frac{1}{R_0}$ then $R$ will become smaller than 1 and the number of infectious individuals will diminish and tend to 0. . Conclusion . This was a brief introduction to compartmentalization models and the dynamics associated with them. . Of course these sort of derivations can be done for many different types of comprtaments and their relevant dynamics, but the SEIR is simple enough to understand and model quickly. .",
            "url": "https://jeffufpost.github.io/scattered-thoughts/modeling/compartmentalization/seir/epidemiology/disease%20dynamics/2020/03/15/compartmentalization.html",
            "relUrl": "/modeling/compartmentalization/seir/epidemiology/disease%20dynamics/2020/03/15/compartmentalization.html",
            "date": " ‚Ä¢ Mar 15, 2020"
        }
        
    
  
    
        ,"post7": {
            "title": "COVID-19 Map",
            "content": ". Link to tracker . Follow this link. . About . There are already many great ways to visualize the spread of sars-cov-2 around the world. I‚Äôve made another one for family and friends that has the world on one page and France on another. . You can click on the countries for more details on the world map. . Likewise you can click on specific departments to see more detail on the French map. . The world map uses data aggregated by the John Hopkins University CSSE. . The french map uses hospitalization and intensive care data from Sante Publique France. . Future blog post about building the site . The site is built using Plotly Dash and deployed to Heroku. . I will likely make a blog post detailing how to build the app and deploy it. .",
            "url": "https://jeffufpost.github.io/scattered-thoughts/covid-19/2020/03/12/COVID-19-Tracker.html",
            "relUrl": "/covid-19/2020/03/12/COVID-19-Tracker.html",
            "date": " ‚Ä¢ Mar 12, 2020"
        }
        
    
  
    
        ,"post8": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master- badges: true- comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . #collapse-hide import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . #collapse-show cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # single-value selection over [Major_Genre, MPAA_Rating] pairs # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(movies).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(movies).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=alt.Y(&#39;IMDB_Rating:Q&#39;, axis=alt.Axis(minExtent=30)), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=600, height=400 ) . Example 3: More Tooltips . # select a point for which to provide details-on-demand label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=700, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; df = pd.read_json(movies) # display table with pandas df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.‚Ü© . 2. This is the other footnote. You can even have a link!‚Ü© .",
            "url": "https://jeffufpost.github.io/scattered-thoughts/jupyter/2020/01/07/test.html",
            "relUrl": "/jupyter/2020/01/07/test.html",
            "date": " ‚Ä¢ Jan 7, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "Electrical engineer by background, but enthusiast of all things data, electronics, governance, development, global health, skiing, football, and many other things. .",
          "url": "https://jeffufpost.github.io/scattered-thoughts/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ ‚Äúsitemap.xml‚Äù | absolute_url }} | .",
          "url": "https://jeffufpost.github.io/scattered-thoughts/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}