{
  
    
        "post0": {
            "title": "Scraping COVID-19 data from data.gouv.fr",
            "content": ". Introduction . As the summary explains, this blog post will very quickly explain how to automatically download French government data on hospitalization and testing pertaining to COVID‚Åª19. . Data sources . Hospitalization data | . The various datasets concerning hospitalization data are found here. . If you follow the link you will find 4 csv datasets concerning hospitalization data along with 5 other csv files with metadata and documentation. . Testing data | . The various datasets concerning testing data are found here. . If you follow the link you will find 2 csv datasets concerning testing data along with 2 other csv files with metadata and documentation. . In both cases we want to download the first of the links since they contain the pertinent daily updated data (do have a look manually at the metadata and documentation files to make sure this is what you want). . Code . #collapse_show # Import libraries used below import requests import urllib.request import urllib.parse import time import io from bs4 import BeautifulSoup import pandas as pd import datetime import os . . Getting the main page . Let&#39;s first have a look ath the main landing page that I provided above. . # Store URL for each page url_cases = &#39;https://www.data.gouv.fr/fr/datasets/donnees-hospitalieres-relatives-a-lepidemie-de-covid-19/&#39; url_tests = &#39;https://www.data.gouv.fr/fr/datasets/donnees-relatives-aux-tests-de-depistage-de-covid-19-realises-en-laboratoire-de-ville/&#39; . # Get response for each URL response_cases = requests.get(url_cases) response_tests = requests.get(url_tests) . The response here should be 200 (see life of codes here). . print(response_cases, response_tests) . &lt;Response [200]&gt; &lt;Response [200]&gt; . # Save the actual content of the page returned with BeautifulSoup soupcases = BeautifulSoup(response_cases.text, &quot;html.parser&quot;) souptests = BeautifulSoup(response_tests.text, &quot;html.parser&quot;) . # Let&#39;s look at the links in the main page (for testing data - if you want cases, replace souptests with soupcases below) for i in range(len(souptests.find_all(&#39;a&#39;, class_=&quot;btn btn-sm btn-primary&quot;))): print(souptests.find_all(&#39;a&#39;, class_=&quot;btn btn-sm btn-primary&quot;)[i].get(&#39;href&#39;)) . None https://www.data.gouv.fr/fr/datasets/r/b4ea7b4b-b7d1-4885-a099-71852291ff20 None https://www.data.gouv.fr/fr/datasets/r/72050bc8-9959-4bb1-88a0-684ff8db5fb5 None https://www.data.gouv.fr/fr/datasets/r/971c5cbd-cd80-4492-b2b3-c3deff8c1f5e None https://www.data.gouv.fr/fr/datasets/r/db378f2a-83a1-40fd-a16c-06c4c8c3535d https://www.data.gouv.fr/fr/datasets/r/49ba79e6-0153-40b1-b050-821e102959eb None https://www.data.gouv.fr/fr/datasets/r/59e82d52-e07a-4ae8-9a49-2d1fd2d2ec21 . We see that the petrtinent file in each cases (testing or hospitalization data) are the first links in their page. So we save only this one as donw below: . # If we want to save that first URL we can do as follows casescsvurl = soupcases.find_all(&#39;a&#39;, class_=&quot;btn btn-sm btn-primary&quot;)[1].get(&#39;href&#39;) testscsvurl = souptests.find_all(&#39;a&#39;, class_=&quot;btn btn-sm btn-primary&quot;)[1].get(&#39;href&#39;) . Getting the CSV data . We now have the URL for the CSV files we want so we&#39;ll do similar steps as above to download these files. . # Similaraly as above, requests.get the CSV URL: rectests = requests.get(testscsvurl) reccases = requests.get(casescsvurl) . What to do with the CSV data . Now that you have the data, what to do with it? . It depends on your purpose I guess: . First write the data to a CSV file which you then read | Directly read the data | . By first writing the CSV file to drive . # This will write the data into cases.csv file # Of course you need to replace the actual path to the folder you want in the code below: with open(os.path.join(&quot;/path/to/folder&quot;, &quot;cases.csv&quot;), &#39;wb&#39;) as f: f.write(reccases.content) . # Same thing for testing data # This will write the data into tests.csv file # Of course you need to replace the actual path to the folder you want in the code below: with open(os.path.join(&quot;/path/to/folder&quot;, &quot;tests.csv&quot;), &#39;wb&#39;) as f: f.write(rectests.content) . # You can then read that csv file to use in your data analysis: tests = pd.read_csv(&#39;tests.csv&#39;, sep=&#39;;&#39;, dtype={&#39;dep&#39;: str, &#39;jour&#39;: str, &#39;clage_covid&#39;: str, &#39;nb_test&#39;: int, &#39;nb_pos&#39;: int, &#39;nb_test_h&#39;: int, &#39;nb_pos_h&#39;: int, &#39;nb_test_f&#39;: int, &#39;nb_pos_f&#39;: int}, parse_dates = [&#39;jour&#39;]) cases = pd.read_csv(&#39;cases.csv&#39;, sep=&#39;;&#39;, dtype={&#39;dep&#39;: str, &#39;jour&#39;: str, &#39;hosp&#39;: int, &#39;rea&#39;: int, &#39;rad&#39;: int, &#39;dc&#39;: int}, parse_dates = [&#39;jour&#39;]) . Note in the code above I had previously looked through the raw csv data to underdstand how to parse it. . Directly reading the data (bypassing the writing CSV file step) . cases = pd.read_csv(io.StringIO(requests.get(casescsvurl).content.decode(&#39;utf-8&#39;)), sep=&#39;;&#39;, dtype={&#39;dep&#39;: str, &#39;jour&#39;: str, &#39;hosp&#39;: int, &#39;rea&#39;: int, &#39;rad&#39;: int, &#39;dc&#39;: int}, parse_dates = [&#39;jour&#39;]) tests = pd.read_csv(io.StringIO(requests.get(testscsvurl).content.decode(&#39;utf-8&#39;)), sep=&#39;;&#39;, dtype={&#39;dep&#39;: str, &#39;jour&#39;: str, &#39;hosp&#39;: int, &#39;rea&#39;: int, &#39;rad&#39;: int, &#39;dc&#39;: int}, parse_dates = [&#39;jour&#39;]) . Other stuff . Parsing/Converting URI into readable format . It sometimes happends that links are provided in URI (URL symbols encoded into % symbols...) . You generally need to convert those back to correct URLs, example below: . # Example URI testurl = &#39;https%3A%2F%2Fstatic.data.gouv.fr%2Fresources%2Fdonnees-hospitalieres-relatives-a-lepidemie-de-covid-19%2F20200505-190040%2Fdonnees-hospitalieres-covid19-2020-05-05-19h00.csv&#39; . # Convert with following line: urllib.parse.unquote(testurl) . &#39;https://static.data.gouv.fr/resources/donnees-hospitalieres-relatives-a-lepidemie-de-covid-19/20200505-190040/donnees-hospitalieres-covid19-2020-05-05-19h00.csv&#39; . A quick look at French testing data from scratch . Let&#39;s quickly see how, from scratch, we can use code above to scrape testing data and plot it quickly. . Note the data only includes city testing centers and does not include hospital testing. . # Use main page URL url_tests = &#39;https://www.data.gouv.fr/fr/datasets/donnees-relatives-aux-tests-de-depistage-de-covid-19-realises-en-laboratoire-de-ville/&#39; response_tests = requests.get(url_tests) . # Find correct CSV file URL souptests = BeautifulSoup(response_tests.text, &quot;html.parser&quot;) testscsvurl = souptests.find_all(&#39;a&#39;, class_=&quot;btn btn-sm btn-primary&quot;)[1].get(&#39;href&#39;) . # Read CSV file into tests variable rectests = requests.get(testscsvurl) tests = pd.read_csv(io.StringIO(requests.get(testscsvurl).content.decode(&#39;utf-8&#39;)), sep=&#39;;&#39;, dtype={&#39;dep&#39;: str, &#39;jour&#39;: str, &#39;hosp&#39;: int, &#39;rea&#39;: int, &#39;rad&#39;: int, &#39;dc&#39;: int}, parse_dates = [&#39;jour&#39;]) . #collapse_hide import plotly.express as px import plotly.graph_objects as go # We want overall testing for France, se we groupby Day and sum: (filtering for clage_covid = 0 means not differentiated between age groups) df = tests[tests.clage_covid==&#39;0&#39;].groupby([&#39;jour&#39;]).sum() fig = go.Figure(data=[ go.Bar(name=&#39;Positive tests&#39;, x=df.index, y=df.nb_pos, marker_color=&#39;red&#39;), go.Bar(name=&#39;Total tests&#39;, x=df.index, y=df.nb_test, marker_color=&#39;blue&#39;) ]) fig.update_layout( title= &#39;Daily positive and total testing data in France&#39;, xaxis_title = &#39;Date&#39;, yaxis_title = &#39;Number of tests (total and positive)&#39;, barmode=&#39;group&#39; ) fig.show() . . . . Conclusion . Very easy to incorporate this into a python script to automate. . This is only the very basic of scraping, a lot more could be done, maybe in another blog post. .",
            "url": "https://jeffufpost.github.io/scattered-thoughts/scraping/covid-19/2020/04/15/web-scraping.html",
            "relUrl": "/scraping/covid-19/2020/04/15/web-scraping.html",
            "date": " ‚Ä¢ Apr 15, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "Testing - what to be aware of",
            "content": ". Motivation for write-up . The real-world motivation for this write-up can be found under Story Time section, but I first wanted to give a bit of theoretical background here. . The importance of testing has been greatly talked about these last few weeks/months with the emergence of the COVID-19 pandemic with numerous articles being published, all underlining the importance of testing. The part emphasized is the fact that early testing allows for quick isolation of sick individuals and tracing of their potential contacts, and thus limiting the potential for spread. . The kind of test for this are called virologic testing and test directly for the presence of virus in an individual (active infection). This is done with Nucleic Acid Tests, or NAT, usually after amplification of the very small amount of genetic material present via Polymerase Chain Reaction. Results are available within hours or days and require diagnostic machinery and specialists. . Knowing who has been infected is also important as it could allow already recovered patients (who are thought to gain immunity from COVID-19) to return safely to work and live basically normally. Tests that check for past infections exist, and are called serology or antibody tests. They check for specific antibodies that match those deveopped during an immune response response against SARS-CoV-2. . This is all good in theory, but with a disease that can cause such serious conditions as COVID-19 can, we need to be sure a positive test means for certain that person is now immmune, or we risk allowing individuals with false positives to return to normal when they should not, and continue the damaging spread of the disease. . The aim of this short right-up is to clear up some misconceptions around testing protocols, discuss the importance of false positives, false negatives, and its importance to guiding public health policies. The idea is basically to answer the following questions: . How many tests should return positive for a person to be, say 95% or 99% person sure he is now immune? | What if a different test is negative? | . Specificity, Sensitivity, False positives, False negatives? . As briefly explained above, neither virological and serological tests are infallible. False positives i.e. healthy individuals with a positive test, and false negatives i.e. infected indiviuals with negative tests, can, and do happen. . There are numerous reasons how and why this can happen, but that is not the point of this write-up. Here, we acknowledge the fact non-perfect tests are a reality and establish testing protocol to deal with that fact. . Thankfully, before being shipped out, the various laboratories test their tests. They are able to characterize them rather precisely and give an indiction of how useful they may be with two important values: . Specificity | Sensitivity | . Specificity . Specificity is the true negative rate - i.e. the percentage of healthy people correctly identified as such (for antibody testing, it is the percentage of people not having antibodies correctly identified as such). . In other words, if a test was used on 100 people who do not have antibodies, the number of people correctly identified as not hvaing antibodies is the specificity. . A perfect test with 100% specificity, means there are no false positives. This has major implications in the current context of COVID-19 pandemic as having an anitbody test with 100% specificity would allow immune people to know so for certain (as long as research showed antibodies gave immunity). . Mathematically, we pose specificity as follows: . $Specificity = frac{True negatives}{True negatives + False posiives}$ . Sensitivity . Sensitivity is the true positive rate - i.e. the percentage of infected people correctly identified as such (for antibody tests, it is the percentage of people having antibodies correctly identified as such). . In other words, if an antibody test was used on 100 people with antibodies, the number of people correctly identified as having anitbodies is the sensitivity. . A perfect test with 100% sensitivity, means there are no false negatives. . Mathematically, we pose specificity as follows: . $Sensitivity = frac{True positives}{True positives + False negatives}$ . Prevalence . Prevalence is simply the proportion of a population that has a certain characteistic. In the current context of antibody testing, the prevalence will be defined as the proportion of people who have antibody conferring immunity to COVID-19 (i.e. the proportion that has had the disease). . $Prevalence = frac{ # People with antibodies}{Total number of people}$ . Where $Total number of people$ is simply $ # People with antibodies + # People without antibodies$ . Story time - Part 1 . Specificity, sensitivity, prevalence, false negatives, false positives.. This is all good, but it can be a bit abstract outside of a specific testing context. . Let&#39;s use the current COVID-19 pandemic as an example. . Antibody tests are finally becoming available to the general population, and you want to know if you&#39;ve had the disease (developped antibodies against it). . Now let&#39;s say you had influenza like symptoms back in January or February, would you expect a positive or negative result on the test? | What if you haven&#39;t been sick but want to check out of curiosity, what result would you expect? | If it does come back positive, how certain would you be that you actually have those antibodies and it wasn&#39;t a false positive? | You decide to use a second test to make sure, again it comes positive. Now how certain are you that you have antibodies? | Out of extreme precaution you decide to try a test from another laboratory (different specificity and sensitivity), and this time the test comes back negative. It&#39;s become a bit more complex to evaluate your situation now. | So how about another test from this second laboratory? Again, negative.. Two positives, two negatives - what can you make of this information? | . However far fetched this scenario may seem, it is exactly what happened to this Florida physician: In January I got very sick (flu like illness but much worse), no sleep for 2 days and almost checked myself into the ED. Had no idea what it was. Today I checked my #COVID19 Antibody status......IgG+ Only (sign of past infection). Mixed emotionsüôÑ. Will retest tomorrow. pic.twitter.com/ExLYi5qPBx . &mdash; Peter Antevy (@HandtevyMD) April 2, 2020 . There are two questions that come out of this story: . After those 4 tests, what is the probability that Dr. Antevy has those antibodies - or more generally, can we calculate the probability of someone having antibodies given their test results? | What should be the threshold of such a probability to minimize the risk of someone without antibodies going out in nature thinking he does ? (obviously if someone has 10 positive tests in a row, it seems sure enough that person has antibodies) This pushes for the need of rigorous testing protocol. | . Calculating probabilites given test results . Clearly, our objective is to calculate the probability that a person has antibodies, or: . $P(seropositive)$ . Conditional probabilities . Baye&#39;s theorem describes probabilities when given evidence. . Say a person has had some COVID-19 symptoms (dry cough, fever, loss of smell, slight fever) a few weeks ago. He might say there is a 75% chance that he had contracted COVID-19, and 25% chance it was another disease. In this case: . $P(seropositive) = 0.75$ . Now this person goes to get an antibody test. What is the probability he is seropositive given a positive or negative result? Baye&#39;s theorem allows us to write it as follows: . $P(seropositive | positive test) = frac{P(positive test | seropositive) * P(seropositive)}{P(positive test)}$ . and . $P(seropositive | negative test) = frac{P(negative test | seropositive) * P(seropositive)}{P(negative test)}$ . Note: . $P(seropositive)$ is called the prior. . $P(seropositive | positive test)$ and $P(seropositive | negative test)$ are called the posterior. . $P(Positive test)$ . Let&#39;s have a look at the probability of getting a positive test - there are 2 ways to get a positive result : . A false positive | A true positive | . $P(False positive) = P(Positive test | seronegative)*P(seronegative)$ . And . $P(True positive) = P(Positive test | seropositive)*P(seropositive)$ . So: . $P(Positive test) = P(Positive test | seropositive)*P(seropositive) + P(Positive test | seronegative)*P(seronegative)$ . Sensitivity and Specificity revisited . Earlier we saw: . $Sensitivity = frac{True positives}{True positives + False negatives}$ . And that . $Specificity = frac{True negatives}{True negatives + False positives}$ . But we can rewrite these equations as follows: . $Sensitivity = P(Positive test | seropositive)$ . And . $Specificity = P(Negative test | seronegative) = 1-P(Positive test | seronegative)$ . Re-writing the posterior probability . Using Baye&#39;s rule and the calculations above we can re-write the posterior equations as follows: . $P(seropositive | Positive test) = frac{Sensitivity*P(seropositive)}{Sensitivity*P(seropositive)+ (1-Specificity)*(1-P(seropositive))}$ . And: . $P(seronegative | Negative test) = frac{Specificity*(1-P(seropositive))}{Specificity*(1-P(seropositive))+(1-Sensitivity)*P(seropositive)}$ . The role of prevalence in these calculations . The equations above describe the probability for an individual given a test result and their prior probability. This prior probability can be estimated given presence or not of symptoms, contact with other infected individuals, location, other diagnostics, etc... . However, on a population level, if we were to test a random individual, this prior becomes the prevalence and for a random individual, the equations become: . $P(seropositive | Positive test) = frac{Sensitivity*Prevalence}{Sensitivity*Prevalence+(1-Specificity)*(1-Prevalence)}$ . And: . $P(seronegative | Negative test) = frac{Specificity*(1-Prevalence)}{Specificity*(1-Prevalence)+(1-Sensitivity)*Prevalence}$ . Serology testing simulation . Let&#39;s see what these equations look like in practice. . #collapse_hide import numpy as np import plotly.express as px import plotly.graph_objects as go . . #collapse_hide # Let&#39;s write a function to output the posterior probability given prior, test result, and test characteristics (sensitivity and specificity) def Pposterior(Pprior, test_res, Sn, Sp): if test_res: return ((Sn * Pprior) / (Sn * Pprior + (1-Sp) * (1-Pprior))) else: return (1-((Sp * (1-Pprior))/(1-(Sn * Pprior + (1-Sp) * (1-Pprior))))) . . Say we have an antibody test with 90% sensitivity and 90% specificity - meaning we have 90% true positives and 90% true negatives, we obtain a graph as below: . #collapse_hide # Below is the prior probability of being infected: num=10000 Pprior = np.linspace((1/num),(num-1)/num,num=num) # Graph the results fig = go.Figure(data=[ go.Scatter(name=&#39;Test negative&#39;, x=100*Pprior, y=100*Pposterior(Pprior, False, 0.9, 0.9), line_color=&quot;green&quot;), go.Scatter(name=&#39;Test positive&#39;, x=100*Pprior, y=100*Pposterior(Pprior, True, 0.9, 0.9), line_color=&quot;red&quot;), go.Scatter(name=&#39;No test&#39;, x=100*Pprior, y=100*Pprior, line_color=&quot;blue&quot;) ]) fig.update_layout( xaxis_title = &#39;Prior probability of being infected&#39;, yaxis_title = &#39;Posterior probability of being infected given test result&lt;br&gt;Specificity=90.0&lt;br&gt;Sensitivity=90.0&#39; ) fig.show() . . . . If you hover the mouse over the lines you can see the exact numbers. . As you can see, a positive or negative test does give more information than no test, but it doesn&#39;t quite give you certainty. . Story time - Part 2 . Let&#39;s circle back to our Dr. Antevy with his two positive tests and the two negative tests. . Prior to any tests, he was about 50% certain of having contracted COVID-19 based on his assesment of his symptoms, location, contact with other people, etc.. . Let&#39;s go through his test results to see what his posterior probability of having antibodies is. . #collapse_hide # Let&#39;s make a new function for multiple tests in a row def PposteriorM(Pprior, test_res): x = Pprior for tr, sn, sp in test_res: if tr == 1: x = (sn * x) / (sn * x + (1-sp) * (1-x)) elif tr == 0: x = (1-((sp * (1-x))/(1-(sn * x + (1-sp) * (1-x))))) return x . . Let&#39;s say these are the characteristics of the tests he used: . Test 1 and 2: Specificity = 0.90 | Sensitivity = 0.99 | . | Test 3 and 4: Specificity = 0.97 | Sensitivity = 0.95 | . | . So a highly sensitive first test followed by a rather good allround test, a bit more specific than the first. . #collapse_hide # Below is the prior probability of being infected: num=10000 Pprior = np.linspace((1/num),(num-1)/num,num=num) # Test characteristics test_results = [(1, 0.99, 0.90),(1, 0.99, 0.90),(0,0.95,0.97),(0,0.95,0.97)] # Graph the results fig = go.Figure(data=[ go.Scatter(name=&#39;1 - 1st positive test&#39;, x=100*Pprior, y=100*PposteriorM(Pprior, [test_results[0]])), go.Scatter(name=&#39;2 - 2nd positive test&#39;, x=100*Pprior, y=100*PposteriorM(Pprior, test_results[0:2])), go.Scatter(name=&#39;3 - 1st negative test&#39;, x=100*Pprior, y=100*PposteriorM(Pprior, test_results[0:3])), go.Scatter(name=&#39;4 - 2nd negative test&#39;, x=100*Pprior, y=100*PposteriorM(Pprior, test_results[0:4])) ]) fig.update_layout( xaxis_title = &#39;Prior probability of being infected&#39;, yaxis_title = &#39;Posterior probability of being infected given test results&#39; ) fig.show() . . . . So let&#39;s go through step-by-step: . Before any test, he was about 50% sure he contracted COVID-19 | After the 1st positive test, this goes up to 90.8% sure | After the 2nd positive test, up to 99.0% sure | But the 1st negative test drops it back to 83.5% | And the 2nd negative all the way down to 20.7% | . What if this was done on a random person in France for example, and all 4 tests were positive. . Then the prior would be the prevalence in France (0.2%) instead of 50%, and the step by step would be as follows: . Before any test, about 0.20% | After 1st positive: still only 1.9% chance of being seropositive | After 2nd positive test: only 16.4% chance of seropositive | After 3rd positive: 86% | And after 4th positive test 99.5% | . So it took about 4 positive tests for a random person in France to become confident enough to be seropositive. . Discussion . The results above strongly underline the need for clear testing protocols and clear understanding of the interpretation of test results. . Wtih a disease that can be so devastating as COVID-19, a few things should be kept in mind: . A high treshold should be used to hedge the risk a false positive | Multiple tests should be taken | Multiple tests with different characteristics (ideally at least one with high sensitivity, and one with high specificity) | .",
            "url": "https://jeffufpost.github.io/scattered-thoughts/covid-19/testing/serology/2020/04/12/on-testing.html",
            "relUrl": "/covid-19/testing/serology/2020/04/12/on-testing.html",
            "date": " ‚Ä¢ Apr 12, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "Epidemic modeling - Part 2",
            "content": ". Motivation for write-up . This is the 2nd part of a multi-part series blog post on modeling in epidemiology. . The COVID-19 pandemic has brought a lot of attention to study of epidemiology and more specifically to the various mathematical models that are used to inform public health policies. Everyone has been trying to understand the growth or slowing of new cases and trying to predict the necessary sanitary resources. This blog post attempts to explain the foundations for some of the most used models and enlighten the reader on two key points. . After introducing the concepts of compartmentalization and disease dynamics in the first blog post, this second part is focused on developing a deterministic numerical solution for the SEIR model discussed there. . Recall SEIR model equations . See the first blog post for derivation. . Continuous-time: . $ frac{dS}{dt}=- beta frac{I(t)}{N}$ | $ frac{dE}{dt}= beta frac{I(t)}{N} - sigma E(t)$ | $ frac{dI}{dt}= sigma E(t) - gamma I(t)$ | $ frac{dR}{dt}= gamma I(t)$ | . | Discrete-time: . $ Delta S = - beta frac{I}{N} * Delta T$ | $ Delta E = ( beta frac{I}{N}- sigma E) Delta T$ | $ Delta I = ( sigma E - gamma I) Delta T$ | $ Delta R = gamma I Delta T$ | . | . Numerical solution to this deteministic population level model . Coding the SEIR model . #collaps_hide import numpy as np import pandas as pd import plotly.express as px import plotly.graph_objects as go . # Let&#39;s build a numerical solution def seir_model(init, parms, days): S_0, E_0, I_0, R_0 = init Epd, Ipd, Rpd = [0], [0], [0] S, E, I, R = [S_0], [E_0], [I_0], [R_0] dt=0.1 t = np.linspace(0,days,int(days/dt)) sigma, beta, gam = parms for _ in t[1:]: next_S = S[-1] - beta*S[-1]*I[-1]*dt Epd.append(beta*S[-1]*I[-1]*dt) next_E = E[-1] + (beta*S[-1]*I[-1] - sigma*E[-1])*dt Ipd.append(sigma*E[-1]*dt) next_I = I[-1] + (sigma*E[-1] - gam*I[-1])*dt Rpd.append(gam*I[-1]*dt) next_R = R[-1] + (gam*I[-1])*dt S.append(next_S) E.append(next_E) I.append(next_I) R.append(next_R) return np.stack([S, E, I, R, Epd, Ipd, Rpd]).T . Trying with average COVID-19 parameters: . Parameters used for plot below: . Days = 100 | Population = 10000 | Number of susceptible people on day 0 = 9999 | Number of exposed people on day 0 = 1 | No infected or recovered people on day 0 | $ sigma = 0.2$ (average of 5 days to go from exposed to infectious) | $ beta = 1.75$ (average of $r=7$ contacts per day and $ rho = 25 %$ chance of a contact with an infectious person resulting in infection) | $ gamma = 0.1$ (average of 10 days to go from infectious to recovered) | . #collapse_hide # Define parameters days = 100 N = 10000 init = 1 - 1/N, 1/N, 0, 0 sigma = 1/5 # 1/5 --&gt; 5 days on average to go from E --&gt; I beta = 1.75 gam = 1/10 # 1/11 --&gt; 11 days on average to go from I --&gt; R parms = sigma, beta, gam # Run simulation results_avg = seir_model(init, parms, days) . . #collapse_hide fig = go.Figure(data=[ go.Scatter(name=&#39;S&#39;, x=np.linspace(0,days,days*10), y=results_avg.T[0], line={&#39;dash&#39;:&#39;solid&#39;, &#39;color&#39;:&#39;blue&#39;}), go.Scatter(name=&#39;E&#39;, x=np.linspace(0,days,days*10), y=results_avg.T[1], line={&#39;dash&#39;:&#39;solid&#39;, &#39;color&#39;:&#39;yellow&#39;}), go.Scatter(name=&#39;I&#39;, x=np.linspace(0,days,days*10), y=results_avg.T[2], line={&#39;dash&#39;:&#39;solid&#39;, &#39;color&#39;:&#39;red&#39;}), go.Scatter(name=&#39;R&#39;, x=np.linspace(0,days,days*10), y=results_avg.T[3], line={&#39;dash&#39;:&#39;solid&#39;, &#39;color&#39;:&#39;green&#39;}), ]) fig.update_layout( xaxis_title = &#39;Day&#39;, yaxis_title = &#39;Proportion of population&#39;, title={ &#39;text&#39;:&#39;Deterministic SEIR model - COVID-19 parameters&#39;, &#39;x&#39;:0.5, &#39;xanchor&#39;:&#39;center&#39; } ) fig.show() . . . . Effects of the different parameters on the SEIR simulation . Effect of $ beta$ ($r* rho$) . Let&#39;s have a look at the effect of $ beta$ on the SEIR simulation. . A higher $ beta$ can either mean a higher average number of contacts per day ($r$) in the population and/or a higher probabilit of transmission of disease from I &rarr; S. . The opposite holds also. . #collapse_hide ## Let&#39;s try to see how the model changes days = 180 N = 10000 init = 1 - 1/N, 1/N, 0, 0 sigma_avg = 1/5 beta_avg = 1.75 beta_noepi = 0.1 beta_low = 0.3 beta_high = 4 gam = 0.1 # 1/10 --&gt; 10 days avergae I --&gt; R parms_avg = sigma_avg, beta_avg, gam parms_noepi = sigma_avg, beta_noepi, gam parms_low = sigma_avg, beta_low, gam parms_high = sigma_avg, beta_high, gam # Run simulation results_avg = seir_model(init, parms_avg, days) results_noepi = seir_model(init, parms_noepi, days) results_low = seir_model(init, parms_low, days) results_high = seir_model(init, parms_high, days) . . #collapse_hide fig = go.Figure(data=[ go.Scatter(name=r&#39;$S: beta_{COVID}$&#39;, x=np.linspace(0,days,days*10), y=results_avg.T[0], line={&#39;dash&#39;:&#39;solid&#39;, &#39;color&#39;:&#39;blue&#39;}, legendgroup=&quot;COVID&quot;), go.Scatter(name=r&#39;$E: beta_{COVID}$&#39;, x=np.linspace(0,days,days*10), y=results_avg.T[1], line={&#39;dash&#39;:&#39;solid&#39;, &#39;color&#39;:&#39;yellow&#39;}, legendgroup=&quot;COVID&quot;), go.Scatter(name=r&#39;$I: beta_{COVID}$&#39;, x=np.linspace(0,days,days*10), y=results_avg.T[2], line={&#39;dash&#39;:&#39;solid&#39;, &#39;color&#39;:&#39;red&#39;}, legendgroup=&quot;COVID&quot;), go.Scatter(name=r&#39;$R: beta_{COVID}$&#39;, x=np.linspace(0,days,days*10), y=results_avg.T[3], line={&#39;dash&#39;:&#39;solid&#39;, &#39;color&#39;:&#39;green&#39;}, legendgroup=&quot;COVID&quot;), go.Scatter(name=r&#39;$S: beta_{noepi}$&#39;, x=np.linspace(0,days,days*10), y=results_noepi.T[0], line={&#39;dash&#39;:&#39;dashdot&#39;,&#39;color&#39;:&#39;blue&#39;}, legendgroup=&quot;noepi&quot;), go.Scatter(name=r&#39;$E: beta_{noepi}$&#39;, x=np.linspace(0,days,days*10), y=results_noepi.T[1], line={&#39;dash&#39;:&#39;dashdot&#39;, &#39;color&#39;:&#39;yellow&#39;}, legendgroup=&quot;noepi&quot;), go.Scatter(name=r&#39;$I: beta_{noepi}$&#39;, x=np.linspace(0,days,days*10), y=results_noepi.T[2], line={&#39;dash&#39;:&#39;dashdot&#39;, &#39;color&#39;:&#39;red&#39;}, legendgroup=&quot;noepi&quot;), go.Scatter(name=r&#39;$R: beta_{noepi}$&#39;, x=np.linspace(0,days,days*10), y=results_noepi.T[3], line={&#39;dash&#39;:&#39;dashdot&#39;, &#39;color&#39;:&#39;green&#39;}, legendgroup=&quot;noepi&quot;), go.Scatter(name=r&#39;$S: beta_{low}$&#39;, x=np.linspace(0,days,days*10), y=results_low.T[0], line={&#39;dash&#39;:&#39;dash&#39;,&#39;color&#39;:&#39;blue&#39;}, legendgroup=&quot;low&quot;), go.Scatter(name=r&#39;$E: beta_{low}$&#39;, x=np.linspace(0,days,days*10), y=results_low.T[1], line={&#39;dash&#39;:&#39;dash&#39;, &#39;color&#39;:&#39;yellow&#39;}, legendgroup=&quot;low&quot;), go.Scatter(name=r&#39;$I: beta_{low}$&#39;, x=np.linspace(0,days,days*10), y=results_low.T[2], line={&#39;dash&#39;:&#39;dash&#39;, &#39;color&#39;:&#39;red&#39;}, legendgroup=&quot;low&quot;), go.Scatter(name=r&#39;$R: beta_{low}$&#39;, x=np.linspace(0,days,days*10), y=results_low.T[3], line={&#39;dash&#39;:&#39;dash&#39;, &#39;color&#39;:&#39;green&#39;}, legendgroup=&quot;low&quot;), go.Scatter(name=r&#39;$S: beta_{high}$&#39;, x=np.linspace(0,days,days*10), y=results_high.T[0], line={&#39;dash&#39;:&#39;dot&#39;, &#39;color&#39;:&#39;blue&#39;}, legendgroup=&quot;high&quot;), go.Scatter(name=r&#39;$E: beta_{high}$&#39;, x=np.linspace(0,days,days*10), y=results_high.T[1], line={&#39;dash&#39;:&#39;dot&#39;, &#39;color&#39;:&#39;yellow&#39;}, legendgroup=&quot;high&quot;), go.Scatter(name=r&#39;$I: beta_{high}$&#39;, x=np.linspace(0,days,days*10), y=results_high.T[2], line={&#39;dash&#39;:&#39;dot&#39;, &#39;color&#39;:&#39;red&#39;}, legendgroup=&quot;high&quot;), go.Scatter(name=r&#39;$R: beta_{high}$&#39;, x=np.linspace(0,days,days*10), y=results_high.T[3], line={&#39;dash&#39;:&#39;dot&#39;, &#39;color&#39;:&#39;green&#39;}, legendgroup=&quot;high&quot;), ]) fig.update_layout( xaxis_title = &#39;Day&#39;, yaxis_title = &#39;Proportion of population&#39;, title={ &#39;text&#39;:r&#39;$ text{Effect of } beta text{on Deterministic SEIR model}$&#39;, &#39;x&#39;:0.5, &#39;xanchor&#39;:&#39;center&#39; } ) fig.show() . . . . We notice a few things from the plot above on the impact of $ beta$: . The higher $ beta$ is: the faster the epidemic seems to propogate in the population | the higher the peak of infected individuals seems to be (meaning a higher chance hospital resources will be saturated) | . | $ beta$ also appears to affect the overall number of people infected over the course of the epidemic - at one point, and keeping all other parameters the same, we reach a point with $ beta &lt; 0.1$ where no epidemic even occurs (more on this later) | . Effect of $ sigma$ (average time from E &rarr; I) . Let&#39;s have a look at the effect of $ sigma$ on the SEIR simulation. . A higher $ sigma$ means shorter average time to go from E &rarr; I. . The opposite holds also. . #collaps_hide ## Let&#39;s try to see how the model changes days = 180 N = 10000 init = 1 - 1/N, 1/N, 0, 0 sigma_fast = 1 # 1 --&gt; Average 1 day from E --&gt; I (ressembles SIR model) sigma_slow = 1/100 #10 days on average, twice as long as COVID-19 sigma_avg = 1/5 beta = 1.75 gam = 0.1 # 1/10 --&gt; 10 days avergae I --&gt; R parms_fastEI = sigma_fast, beta, gam parms_slowEI = sigma_slow, beta, gam parms_avg = sigma_avg, beta, gam # Run simulation results_fastEtoI = seir_model(init, parms_fastEI, days) results_slowEtoI = seir_model(init, parms_slowEI, days) results_avg = seir_model(init, parms_avg, days) . #collaps_hide fig = go.Figure(data=[ go.Scatter(name=r&#39;$S: sigma_{COVID}$&#39;, x=np.linspace(0,days,days*10), y=results_avg.T[0], line={&#39;dash&#39;:&#39;solid&#39;, &#39;color&#39;:&#39;blue&#39;}, legendgroup=&quot;COVID&quot;, hoverinfo=&#39;x+y&#39;), go.Scatter(name=r&#39;$S: sigma_{COVID}$&#39;, x=np.linspace(0,days,days*10), y=results_avg.T[1], line={&#39;dash&#39;:&#39;solid&#39;, &#39;color&#39;:&#39;yellow&#39;}, legendgroup=&quot;COVID&quot;, hoverinfo=&#39;x+y&#39;), go.Scatter(name=r&#39;$S: sigma_{COVID}$&#39;, x=np.linspace(0,days,days*10), y=results_avg.T[2], line={&#39;dash&#39;:&#39;solid&#39;, &#39;color&#39;:&#39;red&#39;}, legendgroup=&quot;COVID&quot;, hoverinfo=&#39;x+y&#39;), go.Scatter(name=r&#39;$S: sigma_{COVID}$&#39;, x=np.linspace(0,days,days*10), y=results_avg.T[3], line={&#39;dash&#39;:&#39;solid&#39;, &#39;color&#39;:&#39;green&#39;}, legendgroup=&quot;COVID&quot;, hoverinfo=&#39;x+y&#39;), go.Scatter(name=r&#39;$S: sigma_{fast}$&#39;, x=np.linspace(0,days,days*10), y=results_fastEtoI.T[0], line={&#39;dash&#39;:&#39;dash&#39;,&#39;color&#39;:&#39;blue&#39;}, legendgroup=&quot;high&quot;, hoverinfo=&#39;x+y&#39;), go.Scatter(name=r&#39;$S: sigma_{fast}$&#39;, x=np.linspace(0,days,days*10), y=results_fastEtoI.T[1], line={&#39;dash&#39;:&#39;dash&#39;, &#39;color&#39;:&#39;yellow&#39;}, legendgroup=&quot;high&quot;, hoverinfo=&#39;x+y&#39;), go.Scatter(name=r&#39;$S: sigma_{fast}$&#39;, x=np.linspace(0,days,days*10), y=results_fastEtoI.T[2], line={&#39;dash&#39;:&#39;dash&#39;, &#39;color&#39;:&#39;red&#39;}, legendgroup=&quot;high&quot;, hoverinfo=&#39;x+y&#39;), go.Scatter(name=r&#39;$S: sigma_{fast}$&#39;, x=np.linspace(0,days,days*10), y=results_fastEtoI.T[3], line={&#39;dash&#39;:&#39;dash&#39;, &#39;color&#39;:&#39;green&#39;}, legendgroup=&quot;high&quot;, hoverinfo=&#39;x+y&#39;), go.Scatter(name=r&#39;$S: sigma_{slow}$&#39;, x=np.linspace(0,days,days*10), y=results_slowEtoI.T[0], line={&#39;dash&#39;:&#39;dot&#39;, &#39;color&#39;:&#39;blue&#39;}, legendgroup=&quot;slow&quot;, hoverinfo=&#39;x+y&#39;), go.Scatter(name=r&#39;$S: sigma_{slow}$&#39;, x=np.linspace(0,days,days*10), y=results_slowEtoI.T[1], line={&#39;dash&#39;:&#39;dot&#39;, &#39;color&#39;:&#39;yellow&#39;}, legendgroup=&quot;slow&quot;, hoverinfo=&#39;x+y&#39;), go.Scatter(name=r&#39;$S: sigma_{slow}$&#39;, x=np.linspace(0,days,days*10), y=results_slowEtoI.T[2], line={&#39;dash&#39;:&#39;dot&#39;, &#39;color&#39;:&#39;red&#39;}, legendgroup=&quot;slow&quot;, hoverinfo=&#39;x+y&#39;), go.Scatter(name=r&#39;$S: sigma_{slow}$&#39;, x=np.linspace(0,days,days*10), y=results_slowEtoI.T[3], line={&#39;dash&#39;:&#39;dot&#39;, &#39;color&#39;:&#39;green&#39;}, legendgroup=&quot;slow&quot;, hoverinfo=&#39;x+y&#39;), ]) fig.update_layout( xaxis_title = &#39;Day&#39;, yaxis_title = &#39;Proportion of population&#39;, title={ &#39;text&#39;:r&#39;$ text{Effect of } sigma text{on Deterministic SEIR model}$&#39;, &#39;x&#39;:0.5, &#39;xanchor&#39;:&#39;center&#39; } ) fig.show() . . . We notice a few things from the plot above on the impact of the average time from E &rarr; I: . The shorter the time, on average, from E &rarr; I: the faster the epidemic propogates in the population | the higher the peak of infected individuals will be (meaning a higher chance hospital resources will be saturated) | . | However, the time from E &rarr; I has no impact on the total number of individuals infected over the entire time of the epidemic (all are enventually infected in any case with these parameters) | . Effect of $ gamma$ (average time from I &rarr; R) . Let&#39;s have a look at the effect of $ gamma$ on the SEIR simulation. . A higher $ gamma$ means shorter average time to go from I &rarr; R. . The opposite holds also. . #collaps_hide ## Let&#39;s try to see how the model changes days = 300 N = 10000 init = 1 - 1/N, 1/N, 0, 0 sigma_avg = 1/5 beta = 1.75 gam_avg = 1/10 # 1/10 --&gt; 10 days average I --&gt; R gam_slow = 1/100 # 1/30 --&gt; 30 days average I --&gt; R gam_fast = 1.5 # 1 --&gt; 1 day average I --&gt; R parms_fastIR = sigma_avg, beta, gam_fast parms_slowIR = sigma_avg, beta, gam_slow parms_avg = sigma_avg, beta, gam_avg # Run simulation results_fastItoR = seir_model(init, parms_fastIR, days) results_slowItoR = seir_model(init, parms_slowIR, days) results_avg = seir_model(init, parms_avg, days) . #collaps_hide fig = go.Figure(data=[ go.Scatter(name=r&#39;$S: gamma_{COVID}$&#39;, x=np.linspace(0,days,days*10), y=results_avg.T[0], line={&#39;dash&#39;:&#39;solid&#39;, &#39;color&#39;:&#39;blue&#39;}, legendgroup=&quot;COVID&quot;, hoverinfo=&#39;x+y&#39;), go.Scatter(name=r&#39;$S: gamma_{COVID}$&#39;, x=np.linspace(0,days,days*10), y=results_avg.T[1], line={&#39;dash&#39;:&#39;solid&#39;, &#39;color&#39;:&#39;yellow&#39;}, legendgroup=&quot;COVID&quot;, hoverinfo=&#39;x+y&#39;), go.Scatter(name=r&#39;$S: gamma_{COVID}$&#39;, x=np.linspace(0,days,days*10), y=results_avg.T[2], line={&#39;dash&#39;:&#39;solid&#39;, &#39;color&#39;:&#39;red&#39;}, legendgroup=&quot;COVID&quot;, hoverinfo=&#39;x+y&#39;), go.Scatter(name=r&#39;$S: gamma_{COVID}$&#39;, x=np.linspace(0,days,days*10), y=results_avg.T[3], line={&#39;dash&#39;:&#39;solid&#39;, &#39;color&#39;:&#39;green&#39;}, legendgroup=&quot;COVID&quot;, hoverinfo=&#39;x+y&#39;), go.Scatter(name=r&#39;$S: gamma_{fast}$&#39;, x=np.linspace(0,days,days*10), y=results_fastItoR.T[0], line={&#39;dash&#39;:&#39;dash&#39;,&#39;color&#39;:&#39;blue&#39;}, legendgroup=&quot;fast&quot;, hoverinfo=&#39;x+y&#39;), go.Scatter(name=r&#39;$S: gamma_{fast}$&#39;, x=np.linspace(0,days,days*10), y=results_fastItoR.T[1], line={&#39;dash&#39;:&#39;dash&#39;, &#39;color&#39;:&#39;yellow&#39;}, legendgroup=&quot;fast&quot;, hoverinfo=&#39;x+y&#39;), go.Scatter(name=r&#39;$S: gamma_{fast}$&#39;, x=np.linspace(0,days,days*10), y=results_fastItoR.T[2], line={&#39;dash&#39;:&#39;dash&#39;, &#39;color&#39;:&#39;red&#39;}, legendgroup=&quot;fast&quot;, hoverinfo=&#39;x+y&#39;), go.Scatter(name=r&#39;$S: gamma_{fast}$&#39;, x=np.linspace(0,days,days*10), y=results_fastItoR.T[3], line={&#39;dash&#39;:&#39;dash&#39;, &#39;color&#39;:&#39;green&#39;}, legendgroup=&quot;fast&quot;, hoverinfo=&#39;x+y&#39;), go.Scatter(name=r&#39;$S: gamma_{slow}$&#39;, x=np.linspace(0,days,days*10), y=results_slowItoR.T[0], line={&#39;dash&#39;:&#39;dot&#39;, &#39;color&#39;:&#39;blue&#39;}, legendgroup=&quot;slow&quot;, hoverinfo=&#39;x+y&#39;), go.Scatter(name=r&#39;$S: gamma_{slow}$&#39;, x=np.linspace(0,days,days*10), y=results_slowItoR.T[1], line={&#39;dash&#39;:&#39;dot&#39;, &#39;color&#39;:&#39;yellow&#39;}, legendgroup=&quot;slow&quot;, hoverinfo=&#39;x+y&#39;), go.Scatter(name=r&#39;$S: gamma_{slow}$&#39;, x=np.linspace(0,days,days*10), y=results_slowItoR.T[2], line={&#39;dash&#39;:&#39;dot&#39;, &#39;color&#39;:&#39;red&#39;}, legendgroup=&quot;slow&quot;, hoverinfo=&#39;x+y&#39;), go.Scatter(name=r&#39;$S: gamma_{slow}$&#39;, x=np.linspace(0,days,days*10), y=results_slowItoR.T[3], line={&#39;dash&#39;:&#39;dot&#39;, &#39;color&#39;:&#39;green&#39;}, legendgroup=&quot;slow&quot;, hoverinfo=&#39;x+y&#39;), ]) fig.update_layout( xaxis_title = &#39;Day&#39;, yaxis_title = &#39;Proportion of population&#39;, title={ &#39;text&#39;:r&#39;$ text{Effect of } gamma text{on Deterministic SEIR model}$&#39;, &#39;x&#39;:0.5, &#39;xanchor&#39;:&#39;center&#39; } ) fig.show() . . . We notice a few things from the plot above on the impact of the average time from I &rarr; R: . The longer the time, on average, from I &rarr; R: the faster the epidemic propogates in the population | the higher the peak of infected individuals will be (meaning a higher chance hospital resources will be saturated) | . | As opposed to the time from E &rarr; I but similarly as $ beta$, the time from I &rarr; R has an impact on the total number of individuals infected over the entire time of the epidemic (with no epidemic if $ gamma &gt; 1.75$ and all other parameters are kept constant) | . Discussion . So we can see the time periods for E &rarr; I and I &rarr; R, along with the value of $ beta$ are critical components in how the model will react. . Notably, no epidemic occurs if $ beta &lt; gamma$ (or if $ frac{ beta}{ gamma} &lt; 1$) . In fact, $ frac{ beta}{ gamma}$ has major implications for the model and is called the basic reproduction number $R_0$. . Hence, if $R_0 &lt; 1$ no epidemic occurs, while the opposite implies an epidemic. . There are major flaws with this model however. While this model is deterministic and uses average time to model $ sigma$ and $ gamma$, this is a major flaw and does not represent the reality for most diseases. . Part 3 of this blog series will discuss this further. .",
            "url": "https://jeffufpost.github.io/scattered-thoughts/modeling/seir/epidemiology/2020/03/18/deterministic-numerical-solutions.html",
            "relUrl": "/modeling/seir/epidemiology/2020/03/18/deterministic-numerical-solutions.html",
            "date": " ‚Ä¢ Mar 18, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "Epidemic modeling - Part 1",
            "content": ". Motivation for write-up . This is the 1st part of a multi-part series blog post on modeling in epidemiology. . The COVID-19 pandemic has brought a lot of attention to study of epidemiology and more specifically to the various mathematical models that are used to inform public health policies. Everyone has been trying to understand the growth or slowing of new cases and trying to predict the necessary sanitary resources. This blog post attempts to explain the foundations for some of the most used models and enlighten the reader on two key points. . In this first post I want to introduce the concept of compartmentalization and how it forms the basis for studying disease dynamics on the population level. . How to model infectious diseases on population level ? . Compartments . When modelling infectious diseases and pandemics in particular, a key ask is to predict the number of infected people at any given time in order to estimate the sanitary resources that will be necessary. . From this simple qestion results the idea of compartmentalization of the population i.e. the division of the population into the two most basic categories: . those that are infected | those that are not | . This is ultimately the foundation for all compartmental models in epidemiology. . The nuances between the models then come from how the above two groups are further compartmentalized. That is to say, how we decide the composition of the infected and the not-infected groups. . The infected group for example could be further sub-categorized into: . asymptomatic | symptomatic | . Or . no treatment necessary | require treatment: local Doctor visit | hospitalization | admitted to intensive care unit | . | . As you can see there are many ways to do this, but the more categories you have, the more difficult it might become to model. Usually we determine these subcategories in order to match available data. . What about the non-infected group? Again there are many ways to subdivide this group but the most obvious first subdivision would be to separate those susceptible to the disease from those that are immune. . Dynamics . While the compartments describe the state any individual can be in at a certain point in time, the dynamics describe the ways in which the compartments interact with each other. . Individual level disease dynamics . This describes on the individual level, how one person can go from one state to another (one compartment to another) i.e. a healthy person becomes ill, then he dies or recovers, etc.. . Population-level dynamics . This describes on a population level how the total number of individuals in each compartment vary over time. . We will see more on this in other blog posts. . A simple example - the SIR model . Let&#39;s have a look at a basic compartmental model, the SIR model. . S --&gt; Susceptible state: | . An S individual is simply someone susceptible to the disease, that is anyone in the population who is healthy and not immune to the disease. . I --&gt; Infectious state: | . Once an individual is exposed to the disease he will develop this disease and become infectious. . R --&gt; Recovered state: | . An individual will either fight off the infection (with the help or not of treatment) or die. These are all included in the R state. . In the basic SIR model, anyone R has aquired full and infinite immunity and cannot catcht the disease again (of course many variations can be included to reflect more closely a disease). . In this write-up we will focus on the SEIR models, which are similar to the SIR compartments above with the additional E state between S and I. . E --&gt; Exposed state: | . The exposed state is the state when an individual has been exposed to the disease, but has not become infectious yet. . It should be noted the incubation period, the time between exposure to disease and development of the disease is not necessarily the same as the time between the states E and I. Indeed, an individual may become infectious before the appearance of the symptoms (or at the same time, or after, but not necessarily the same time). . Individual-level disease dynamic . As explained above, the individual-level disease dynamic describes the progression of disease within an individual i.e. the progression of an individual from one state to another. . In the models used here (SEIR model), an individual starts at S (although an initial exposed or infectious person is injected into the population at time t=0). . | If exposed to the disease he will move into the state E. . | After which he will move to the I state with probability 1, but in a time unique to himself. . | Again after which he will move into the state R with probability 1, and again in a time unique to him. . | From state R he will stay in state R (either dead or has aquired full and inifite immunity). . | . Let&#39;s have a closer look: . S &rarr; E . The chances of an individual going from S &rarr; E depends on three things: . the number of contacts the person has per unit time (given by $r$) | the chance a given contact is with an I - infectious individual (the higher thenumber of I, the higher the chance) | the chance of an S contracting the disease from a contact with an I (given by $ rho$) | E &rarr; I . All people exposed will eventually develop disease. . However, individually, a person might go from E to I on the first day, or after 10 days, this is unique to the individual. . Everyday additional day following exposure the probability of this individual to go from E &rarr; I increases (we will have a look at the probaility distribution and its importance later). . I &rarr; R . Similarly, all infectious people will recover (or die). Again, individually, a person might go from I to R in 5 days or in 15 days, this time is the recovery time and is proper to the individual. . Population level dynamics . Most basic models tend to disregard the notion of individual dynamics above in favor of poopulation level dynamics. That is to say the models tend to model disease on a population level without looking at the specifics pogression of disease within the individuals and using averages instead (although the S &rarr; E uses the same logic as above). . Below is an explanation for such an SEIR model with its mathematical formulation. . Note no births or deaths are included. . S &rarr; E . As stated above, going from S to E depends on: . the number of infectious people in the population: $ frac{I(t)}{N}$ | the average number of contacts an individual has per day: $r$ | the chance for an S to contract the disease after contact with an I: $ rho$ | . We can combine the last two into $ beta = r * rho$ . So the negative rate of change of the number of S in a population over a unit time is equal to $ beta * frac{I(t)}{N}$ . Hence we can formulate this mathematically as follows: . $ Delta S = - beta frac{I}{N} * Delta T$ . or . $ frac{dS}{dt}=- beta frac{I(t)}{N}$ . E &rarr; I . We have seen above how each individual goes from E to I. . On a population level, the number of E changes in two ways: . new additions following S &rarr; E | reduction following E &rarr; I | . We know the number from S &rarr; E is: $ beta frac{I(t)}{N}$ . How can we model the number of E &rarr; I? . While individually this is complicated to model and pertains to the specific probability distribution, on a population level we can use the average time it takes - this is what most models do (part 3 of this blog post will show why this is wrong for COVID-19). . Let&#39;s say average time from E &rarr; I is $ frac{1}{ sigma}$, then we know every unit time, we have $ sigma * E$ transitions from E &rarr; I. . Mathematically, we write this as : . $ Delta E = ( beta frac{I}{N}- sigma E) Delta T$ . or . $ frac{dE}{dt}= beta frac{I(t)}{N} - sigma E(t)$ . I &rarr; R . Similarly as above, we have seen above how each individual goes from I to R but this does not tell us about the population level dynamics. . On a population level, the number of I changes in two ways: . new additions following E &rarr; I | reduction following I &rarr; R | . We know the number from E &rarr; I is: $ sigma E(t)$ . How can we model the number of I &rarr; R? . Again, while individually this is complicated, on a population level, how about averaging it out, this is what most models do. Let&#39;s say average time from I &rarr; R is $ frac{1}{ gamma}$, then we have: . $ Delta I = ( sigma E - gamma I) Delta T$ . or . $ frac{dI}{dt}= sigma E(t) - gamma I(t)$ . R &rarr; R . Finally, we can model the number of individuals in R state with the following equation: . $ Delta R = gamma I Delta T$ . or . $ frac{dR}{dt}= gamma I(t)$ . Conclusion . A brief introduction to compartmentalization models and the dynamics associated with them. . Of course these sort of derivations can be done for many different types of comprtaments and their relevant dynamic models, but the SEIR is simple enough to understand and model quickly. . Please note for COVID-19, the assumptions of averaging out the times for E &rarr; I and I &rarr; R are not correct ! . While many models have been published like this for COVID, they cannot be correct and this will be shown in part 3 of these series. .",
            "url": "https://jeffufpost.github.io/scattered-thoughts/modeling/compartmentalization/seir/epidemiology/disease%20dynamics/2020/03/15/compartmentalization.html",
            "relUrl": "/modeling/compartmentalization/seir/epidemiology/disease%20dynamics/2020/03/15/compartmentalization.html",
            "date": " ‚Ä¢ Mar 15, 2020"
        }
        
    
  
    
        ,"post4": {
            "title": "COVID-19 Map",
            "content": ". Link to tracker . Follow this link. . About . There are already many great ways to visualize the spread of sars-cov-2 around the world. I‚Äôve made another one for family and friends that has the world on one page and France on another. . You can click on the countries for more details on the world map. . Likewise you can click on specific departments to see more detail on the French map. . The world map uses data aggregated by the John Hopkins University CSSE. . The french map uses hospitalization and intensive care data from Sante Publique France. . Future blog post about building the site . The site is built using Plotly Dash and deployed to Heroku. . I will likely make a blog post detailing how to build the app and deploy it. .",
            "url": "https://jeffufpost.github.io/scattered-thoughts/covid-19/2020/03/12/COVID-19-Tracker.html",
            "relUrl": "/covid-19/2020/03/12/COVID-19-Tracker.html",
            "date": " ‚Ä¢ Mar 12, 2020"
        }
        
    
  
    
        ,"post5": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master- badges: true- comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . #collapse-hide import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . #collapse-show cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # single-value selection over [Major_Genre, MPAA_Rating] pairs # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(movies).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(movies).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=alt.Y(&#39;IMDB_Rating:Q&#39;, axis=alt.Axis(minExtent=30)), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=600, height=400 ) . Example 3: More Tooltips . # select a point for which to provide details-on-demand label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=700, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; df = pd.read_json(movies) # display table with pandas df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.‚Ü© . 2. This is the other footnote. You can even have a link!‚Ü© .",
            "url": "https://jeffufpost.github.io/scattered-thoughts/jupyter/2020/01/07/test.html",
            "relUrl": "/jupyter/2020/01/07/test.html",
            "date": " ‚Ä¢ Jan 7, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "Electrical engineer by background, but enthusiast of all things data, electronics, governance, development, global health, skiing, football, and many other things. .",
          "url": "https://jeffufpost.github.io/scattered-thoughts/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ ‚Äúsitemap.xml‚Äù | absolute_url }} | .",
          "url": "https://jeffufpost.github.io/scattered-thoughts/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}